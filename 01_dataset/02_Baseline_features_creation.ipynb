{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0be99b0d-5b70-43ab-bff3-c7d27d2ab547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from sentimentpl.models import SentimentPLModel\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from helpers.dataset import (\n",
    "    deal_with_polish_sign,\n",
    "    clean_text,\n",
    "    get_stylometric_features\n",
    ")\n",
    "\n",
    "nlp_core = spacy.load(\"pl_core_news_lg\")\n",
    "model_sent = SentimentPLModel(from_pretrained='latest')\n",
    "stopwords = nlp_core.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d0324-9434-44a3-86a2-be760e911763",
   "metadata": {},
   "source": [
    "# Read data & clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e730b2f-ede1-44f2-aeb8-71893f7478a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/demagog_nlp_cz/converted-exp-PL.tsv', sep='\\t')\n",
    "\n",
    "df['text_clean'] = df['statementText'].apply(lambda x: clean_text(x))\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: deal_with_polish_sign(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22ff5b-b084-4bd3-9236-1477d02609fd",
   "metadata": {},
   "source": [
    "# Filter not TRUE/FALSE cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a2bd81e-b29f-46a2-a615-12b3dbb59e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statementState\n",
       "TRUE            1761\n",
       "FALSE            648\n",
       "MISLEADING       313\n",
       "UNVERIFIABLE     113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['statementState'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "756ceec0-8a34-40b3-8598-aa8d132ade0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ df['statementState'] != 'MISLEADING' ]\n",
    "df = df[ df['statementState'] != 'UNVERIFIABLE' ]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['assestment'] = df['statementState'].replace({\n",
    "    'FALSE' : 1,\n",
    "    'TRUE' : 0\n",
    "}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ab686-7575-4f6c-8c9d-72a73fbc8531",
   "metadata": {},
   "source": [
    "# Stylommetric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25c7584c-78ce-4c91-a572-7ddfa3d8c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Add WORDS ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2409/2409 [00:17<00:00, 138.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Add POS ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2409/2409 [00:16<00:00, 142.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df = get_stylometric_features(df,  nlp_core, model_sent, stopwords, 'text_clean', rerun_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a11f9e92-1c34-4d2d-a931-fe1b5787c518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['politicianID', 'name', 'party', 'statementID', 'statementText',\n",
       "       'statementState', 'statementExplanClean', 'statementExplan',\n",
       "       'text_clean', 'assestment', 'TEXT_WORD', 'TEXT_POS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b0300-848f-4b0b-ab59-90c019282800",
   "metadata": {},
   "source": [
    "## Save stylommetric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fd8595d-ba2a-4053-85b3-516008c278ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['assestment']\n",
    "\n",
    "stylo_features = [\n",
    "    'avg_word_len', 'n_words', 'n_char', 'n_special_char',\n",
    "    'avg_n_vowels_per_word', 'hapax_legomena', 'hapax_dislegemena',\n",
    "    'honore_r', 'sichel_s', 'brunet_w', 'yule_k', 'shannon_entropy',\n",
    "    'simpson_idx_d', 'type_token_ratio', 'FR_score', 'FKG_level',\n",
    "    'Gunning_Fog_index', 'sentiment_all', 'sentiment_avg', 'n_stop_words',\n",
    "    'n_ent', 'p_adj', 'n_adj', 'p_adv', 'n_adv', 'p_noun', 'n_noun'\n",
    "]\n",
    "\n",
    "cols_for_other_f = ['text_clean', 'TEXT_WORD', 'TEXT_POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efabae90-754d-4eb9-8fa0-0e40b744d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[target_column+stylo_features].to_parquet('../datasets/used_data/02_classical_ml/02_01_benchmark_styllometric_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13ee50-2f29-48db-ae9e-843fc9cb99e0",
   "metadata": {},
   "source": [
    "# Ngrams POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2b0abdc-ee4b-4a99-b64c-5693e965962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = 5\n",
    "min_pos = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52255441-5ab9-4bfd-8ad5-a44d0bb3b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4649/4649 [00:24<00:00, 190.59it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pos = df[target_column].copy()\n",
    "\n",
    "words =  sum(df['TEXT_POS'].str.split(' ').values.tolist(), [])\n",
    "\n",
    "n_list = []\n",
    "for n in range(n_grams):\n",
    "    n_i = pd.Series(nltk.ngrams(words, n+1)).value_counts()\n",
    "    n_i = n_i[n_i>min_pos]\n",
    "    n_list.append(n_i)\n",
    "\n",
    "n_iterator = []\n",
    "for n_i in n_list:\n",
    "    n_iterator += n_i.index.tolist()\n",
    "    \n",
    "col = {}\n",
    "    \n",
    "for n in tqdm(n_iterator):\n",
    "    x = df['TEXT_POS'].str.count(' '.join(n)) / df['TEXT_POS'].str.split(' ').str.len()\n",
    "\n",
    "    col[' '.join(n)] = x\n",
    "    col[' '.join(n)].name = ' '.join(n)\n",
    "            \n",
    "df_pos = pd.concat( [df_pos] + list( col.values() ), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c352c5c-ed4a-47ef-bb3a-84e3e37b3713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2409, 4650)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "444f2591-e37d-49f5-ae0b-80a7730961ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos.to_parquet('../datasets/used_data/02_classical_ml/02_02_benchmark_POS_ngrams.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0a6b3-35b2-4d73-91a4-31aac9f99507",
   "metadata": {},
   "source": [
    "# Ngram words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15a607c0-e249-4ef7-9ed2-e1b4452e28b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1172/1172 [00:05<00:00, 206.61it/s]\n"
     ]
    }
   ],
   "source": [
    "df_ngram = df[target_column + ['TEXT_WORD']].copy()\n",
    "\n",
    "words =  sum(df['TEXT_WORD'].str.split(' ').values.tolist(), [])\n",
    "\n",
    "n_list = []\n",
    "for n in range(n_grams):\n",
    "    n_i = pd.Series(nltk.ngrams(words, n+1)).value_counts()\n",
    "    n_i = n_i[n_i>min_pos]\n",
    "    n_list.append(n_i)\n",
    "\n",
    "n_iterator = []\n",
    "for n_i in n_list:\n",
    "    n_iterator += n_i.index.tolist()\n",
    "\n",
    "col = {}\n",
    "    \n",
    "for n in tqdm(n_iterator):\n",
    "    x = df['TEXT_WORD'].str.count(' '.join(n)) / df['TEXT_WORD'].str.split(' ').str.len()\n",
    "\n",
    "    col[' '.join(n)] = x\n",
    "    col[' '.join(n)].name = ' '.join(n)\n",
    "            \n",
    "df_ngram = pd.concat( [df_ngram] + list( col.values() ), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c560cd7-e411-4ae7-a1e6-93c7f656e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2409, 1174)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a1578b7-020f-46dc-baea-b9553612dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram.to_parquet('../datasets/used_data/02_classical_ml/02_03_benchmark_words_ngrams.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ba959-0cf8-4e58-a8df-f228e34ae7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
