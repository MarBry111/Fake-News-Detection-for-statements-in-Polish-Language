{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3587c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marek/anaconda3/envs/nlp/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 7 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "# import morfeusz2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import utils\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import shap\n",
    "\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=7,progress_bar=True)\n",
    "\n",
    "from parallelbar import progress_map\n",
    "\n",
    "\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim import corpora\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.base import clone as sklearn_clone\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148d9d1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e578f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/ready2use/fake_news_features_cz.csv', sep=';')\n",
    "\n",
    "df = df[ df['statementState'] != 'MISLEADING' ]\n",
    "df = df[ df['statementState'] != 'UNVERIFIABLE' ]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['assestment'] = df['statementState'].replace({\n",
    "    'FALSE' : 0,\n",
    "#     'Manipulacja' : 1,\n",
    "    'TRUE' : 1\n",
    "}).astype(int)\n",
    "\n",
    "y_train = df.copy()['assestment']\n",
    "X_train = df.copy().loc[:, df.columns != 'assestment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbfd960",
   "metadata": {},
   "source": [
    "## Analysis words frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb05184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f9634e469f446989726e8d156a1978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 1:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd4154fae2b44b78e57df00bee6cff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 2:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64996d3d4b00489d8e3515f9278b61e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 3:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77b64e10cc14c9a95c478f1c20bac7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 4:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8d8a1db1174797a3b89e39cfd86823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 5:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b14418fc244efdb7fbb5ded6108257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 6:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f87b5df0363408bb25c68b47524c862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 7:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = X_train['text_clean'].values.tolist()\n",
    "result = progress_map(tokenize, tasks, n_cpu=7, chunk_size=1, core_progress=True)\n",
    "\n",
    "X_train['words'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9d6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one = X_train.copy()\n",
    "\n",
    "# df_one = df_one[['tokens']].reset_index().explode('tokens')\n",
    "df_one = df_one[['words']].reset_index().explode('words')\n",
    "df_one['n'] = 1\n",
    "df_one['tokens'] = df_one['words'].apply( lambda x: re.sub(r\"[`'-.â€™0-9]\", \"\", x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317fd651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_one = df_one[df_one['tokens'].str.len() > 1]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6,8));\n",
    "df_one.groupby('tokens').agg(n=('n','sum')).sort_values('n').tail(30).plot(kind='barh', ax=ax)\n",
    "plt.title('Trainig set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3acaae",
   "metadata": {},
   "source": [
    "### Remove extra stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e21c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stop_words = set(['polska', \n",
    "                        'rok', \n",
    "                        'milion', \n",
    "                        'miliard', \n",
    "                        'polski', 'europejski', \n",
    "                        'prezydent', 'rzÄ…d', 'ustawa', 'procent', 'kraj'] \n",
    "                       + \n",
    "                       df_one.groupby('tokens').agg(n=('n','sum')).query('n<6').index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b48e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddc9a3801904b4d9c4e9ed7ca90347a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 1:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43fa4dfb71d4b72a1e077da1cb4611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 2:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c3892903ba4616aa6582ef242cc66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 3:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e8f6c168b6423bb67dca26bc12abc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 4:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5722790ea754515aa513e5fe9cd30ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 5:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f65c24f0ab4d77978e249e8f17b0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 6:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2179f6b99bc455eb877c04f363f1e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 7:   0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_stop_words(words, stop_words = extra_stop_words):\n",
    "    out = [x for x in words if x not in stop_words]\n",
    "    return out\n",
    "\n",
    "tasks = X_train['words'].values.tolist()\n",
    "result = progress_map(filter_stop_words, tasks, n_cpu=7, chunk_size=1, core_progress=True)\n",
    "\n",
    "X_train['words_clean'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0985a23",
   "metadata": {},
   "source": [
    "### Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c2a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = 5\n",
    "min_pos = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5926e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4579/4579 [00:50<00:00, 91.03it/s]\n"
     ]
    }
   ],
   "source": [
    "X_pos = X_train[['TEXT_POS']].copy()\n",
    "\n",
    "words =  sum(X_pos['TEXT_POS'].str.split(' ').values.tolist(), [])\n",
    "\n",
    "n_list = []\n",
    "for n in range(n_grams):\n",
    "    n_i = pd.Series(nltk.ngrams(words, n+1)).value_counts()\n",
    "    n_i = n_i[n_i>min_pos]\n",
    "    n_list.append(n_i)\n",
    "\n",
    "n_iterator = []\n",
    "for n_i in n_list:\n",
    "    n_iterator += n_i.index.tolist()\n",
    "    \n",
    "col = {}\n",
    "    \n",
    "for n in tqdm(n_iterator):\n",
    "    x = X_pos['TEXT_POS'].str.count(' '.join(n)) / X_pos['TEXT_POS'].str.split(' ').str.len()\n",
    "\n",
    "    col[' '.join(n)] = x\n",
    "    col[' '.join(n)].name = ' '.join(n)\n",
    "            \n",
    "X_pos = pd.concat( [X_pos] + list( col.values() ), axis=1 ).drop('TEXT_POS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea2ac656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1117/1117 [00:09<00:00, 123.76it/s]\n"
     ]
    }
   ],
   "source": [
    "X_ngram = X_train[['words_clean']].copy()\n",
    "\n",
    "X_ngram['words_clean'] = X_ngram['words_clean'].apply(lambda l: \" \".join(l))\n",
    "\n",
    "words =  sum(X_ngram['words_clean'].str.split(' ').values.tolist(), [])\n",
    "\n",
    "n_list = []\n",
    "for n in range(n_grams):\n",
    "    n_i = pd.Series(nltk.ngrams(words, n+1)).value_counts()\n",
    "    n_i = n_i[n_i>min_pos]\n",
    "    n_list.append(n_i)\n",
    "\n",
    "n_iterator = []\n",
    "for n_i in n_list:\n",
    "    n_iterator += n_i.index.tolist()\n",
    "\n",
    "col = {}\n",
    "    \n",
    "for n in tqdm(n_iterator):\n",
    "    x = X_ngram['words_clean'].str.count(' '.join(n)) / X_ngram['words_clean'].str.split(' ').str.len()\n",
    "\n",
    "    col[' '.join(n)] = x\n",
    "    col[' '.join(n)].name = ' '.join(n)\n",
    "            \n",
    "X_ngram = pd.concat( [X_ngram] + list( col.values() ), axis=1 ).drop('words_clean', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20c751",
   "metadata": {},
   "source": [
    "## Make balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5343ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_0 = y_train.value_counts()[0]\n",
    "n_1 = y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c7b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lower = y_train.value_counts().min()\n",
    "n_upper = y_train.value_counts().max()\n",
    "\n",
    "np.random.seed(111)\n",
    "\n",
    "if True:\n",
    "    # undersampling    \n",
    "    index_0 = np.random.choice(y_train[y_train==0].index, n_lower, replace=False)\n",
    "    index_1 = np.random.choice(y_train[y_train==1].index, n_lower, replace=False)\n",
    "\n",
    "    y_train_u = y_train.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    \n",
    "    X_train_u = X_train.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_pos_u = X_pos.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_ngram_u = X_ngram.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "else:\n",
    "    # oversampling\n",
    "    if n_0 < n_1:\n",
    "        index_0 = np.random.choice(y_train[y_train==0].index, n_1, replace=True)\n",
    "        index_1 = np.random.choice(y_train[y_train==1].index, n_1, replace=False)\n",
    "    else:\n",
    "        index_0 = np.random.choice(y_train[y_train==0].index, n_0, replace=False)\n",
    "        index_1 = np.random.choice(y_train[y_train==1].index, n_0, replace=True)\n",
    "\n",
    "    y_train_u = y_train.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    \n",
    "    X_train_u = X_train.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_pos_u = X_pos.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_ngram_u = X_ngram.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cd3dc",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50ce758",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load(\"../word2vec/word2vec_100_3_polish.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbffe782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa59248aec37486387fb59b51aba33ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 1:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe4ab2329e405cacd873a681ce7e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 2:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b02f73b454492189547d5b8fbc9f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 3:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc082e601bf43b38e9a9ae1b46ec40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 4:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d282df287b664af0ae774490b9258f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 5:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3403e28180bb4655b0f703d6d4e4254e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 6:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b5964df3f949938317bc0b7d2c74aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Core 7:   0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_wor2vec_embeddings(words, w2v=word2vec):\n",
    "    emb = []\n",
    "    for x in words:\n",
    "        if x in word2vec.index_to_key:\n",
    "            emb.append( w2v[x].reshape(1,-1) )\n",
    "        else:\n",
    "            emb.append( np.zeros((1,100)) )\n",
    "    \n",
    "    if len(emb) == 0:\n",
    "        out = np.zeros((1,100))\n",
    "    else:\n",
    "        out = np.concatenate(emb, axis=0)\n",
    "    \n",
    "    return out\n",
    "\n",
    "tasks = X_train_u['words_clean'].values.tolist()\n",
    "result = progress_map(get_wor2vec_embeddings, tasks, n_cpu=7, chunk_size=1, core_progress=True)\n",
    "\n",
    "X_train_u['wor2vec'] = result\n",
    "\n",
    "X_w2v = X_train_u[['words_clean', 'wor2vec']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c34bd",
   "metadata": {},
   "source": [
    "## CV creation\n",
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74ee952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_topic_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02f856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1296/1296 [00:00<00:00, 5589.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(X_train_u['words_clean'].values)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in X_train_u['words_clean'].values]\n",
    "\n",
    "\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = ideal_topic_num, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   random_state=111,\n",
    "                                   workers = 7)\n",
    "\n",
    "topics = []\n",
    "\n",
    "for line in tqdm(X_train_u['words_clean'].values):\n",
    "    line_bow = dictionary.doc2bow(line)\n",
    "    doc_lda = lda_model[line_bow]\n",
    "    \n",
    "    topics.append( max(doc_lda, key=lambda x:x[1])[0] )\n",
    "\n",
    "X_train_u['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd65141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.030*\"miejsce\" + 0.025*\"osoba\" + 0.024*\"tysiÄ…c\" + 0.017*\"czÅ‚owiek\" + 0.013*\"dziecko\"\n",
      "1 0.022*\"partia\" + 0.015*\"deficyt\" + 0.014*\"drugi\" + 0.011*\"pis\" + 0.010*\"projekt\"\n",
      "2 0.040*\"wybory\" + 0.034*\"trybunaÅ‚\" + 0.026*\"konstytucyjny\" + 0.018*\"przyp\" + 0.016*\"dzieÅ„\"\n",
      "3 0.028*\"budÅ¼et\" + 0.019*\"pkb\" + 0.016*\"unia\" + 0.014*\"paÅ„stwo\" + 0.013*\"tysiÄ…c\"\n",
      "4 0.019*\"rocznie\" + 0.015*\"sprawa\" + 0.012*\"platforma\" + 0.012*\"pis\" + 0.012*\"komorowski\"\n",
      "5 0.020*\"sÄ™dzia\" + 0.014*\"czÅ‚owiek\" + 0.012*\"zÅ‚oty\" + 0.011*\"unia\" + 0.011*\"jedyny\"\n",
      "6 0.024*\"liczba\" + 0.016*\"minister\" + 0.015*\"osoba\" + 0.010*\"janusz\" + 0.010*\"europa\"\n",
      "7 0.034*\"euro\" + 0.014*\"the\" + 0.013*\"pierwszy\" + 0.011*\"czas\" + 0.011*\"podatek\"\n",
      "8 0.032*\"polak\" + 0.016*\"zostaÄ‡\" + 0.015*\"ukraina\" + 0.014*\"praca\" + 0.014*\"poziom\"\n",
      "9 0.015*\"bezrobocie\" + 0.015*\"program\" + 0.011*\"nowy\" + 0.011*\"podatek\" + 0.011*\"zÅ‚oty\"\n"
     ]
    }
   ],
   "source": [
    "x=lda_model.show_topics(num_topics=ideal_topic_num, num_words=5)\n",
    "\n",
    "for topic,word in x:\n",
    "    print(topic, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9351146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>assestment</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "assestment   0   1\n",
       "topic             \n",
       "0           80  57\n",
       "1           48  55\n",
       "2           54  75\n",
       "3           78  86\n",
       "4           57  66\n",
       "5           81  73\n",
       "6           53  52\n",
       "7           67  61\n",
       "8           68  61\n",
       "9           62  62"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_u_test = pd.DataFrame(y_train_u.copy())\n",
    "y_train_u_test['topic'] = X_train_u['topic']\n",
    "y_train_u_test['n'] = 1\n",
    "y_train_u_test.groupby(['topic', 'assestment']).sum().reset_index().pivot('topic','assestment','n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e17e0a",
   "metadata": {},
   "source": [
    "### Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8829acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fold = []\n",
    "cv_fold_i = []\n",
    "\n",
    "for i in X_train_u['topic'].unique().reshape(10,-1):\n",
    "    train_cv = X_train_u.index[ ~np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    test_cv = X_train_u.index[ np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    \n",
    "    train_cv_i = X_train_u.reset_index().index[ ~np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    test_cv_i = X_train_u.reset_index().index[ np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    \n",
    "    cv_fold.append( [train_cv, test_cv])\n",
    "    cv_fold_i.append( [train_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bec90100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "kf.get_n_splits(X_train_u)\n",
    "\n",
    "cv_Kfold = []\n",
    "cv_Kfold_i = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_u):\n",
    "    train_cv = X_train_u.iloc[ train_index, : ].index.values\n",
    "    test_cv = X_train_u.iloc[ test_index, : ].index.values\n",
    "\n",
    "    train_cv_i= X_train_u.reset_index().iloc[ train_index, : ].index.values\n",
    "    test_cv_i = X_train_u.reset_index().iloc[ test_index, : ].index.values\n",
    "    \n",
    "    cv_Kfold.append( [train_cv, test_cv])\n",
    "    cv_Kfold_i.append( [train_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0f426",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ff6e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, y, cv, clf_org, r_min=0.05):\n",
    "\n",
    "    results = {\n",
    "        'test_accuracy' : [],\n",
    "        'test_precision' : [],\n",
    "        'test_recall' : [],\n",
    "        'test_f1' : []\n",
    "    }\n",
    "\n",
    "    c_matrix = np.zeros((2,2))\n",
    "\n",
    "    for train_cv, test_cv in cv:\n",
    "        clf = sklearn_clone(clf_org)\n",
    "    #     clf = RandomForestClassifier(random_state=111)\n",
    "\n",
    "        X_train_t = X[X.index.isin(train_cv)]\n",
    "        y_train_t = y[y.index.isin(train_cv)]\n",
    "\n",
    "        # keep only columns with corr > 0.05\n",
    "        col_keep = []\n",
    "        for c in X_train_t.columns:\n",
    "            min_v =X_train_t[c].values.min()\n",
    "            max_v = X_train_t[c].values.max()\n",
    "\n",
    "            if min_v < max_v:\n",
    "                r = scipy.stats.pearsonr(X_train_t[c].values, y_train_t)[0]\n",
    "                if ~np.isnan(r) and r > r_min:\n",
    "                    col_keep.append(c)\n",
    "        \n",
    "        if len(col_keep) == 0:\n",
    "            print('No values returned')\n",
    "        \n",
    "        X_train_t = X_train_t[col_keep]\n",
    "\n",
    "\n",
    "        X_test_t = X[X.index.isin(test_cv)]\n",
    "        y_test_t = y[y.index.isin(test_cv)]\n",
    "\n",
    "        X_test_t = X_test_t[col_keep]\n",
    "\n",
    "        clf.fit(X_train_t, y_train_t)\n",
    "\n",
    "        y_pred = clf.predict(X_test_t)\n",
    "\n",
    "        confusion = confusion_matrix(y_test_t, y_pred)\n",
    "        c_matrix += confusion\n",
    "\n",
    "    #     TN, FP = confusion[0, 0], confusion[0, 1]\n",
    "    #     FN, TP = confusion[1, 0], confusion[1, 1]\n",
    "\n",
    "        results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "        results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "        results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "        results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": np.array(results['test_accuracy']),\n",
    "    #     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "    #     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "        \"F1 Score\":  np.array(results['test_f1']),\n",
    "        }\n",
    "\n",
    "#     print(c_matrix)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496178a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_w2v(X, y, cv, clf_org):\n",
    "\n",
    "    results = {\n",
    "        'test_accuracy' : [],\n",
    "        'test_precision' : [],\n",
    "        'test_recall' : [],\n",
    "        'test_f1' : []\n",
    "    }\n",
    "\n",
    "    c_matrix = np.zeros((2,2))\n",
    "\n",
    "    for train_cv, test_cv in cv:\n",
    "        clf = sklearn_clone(clf_org)\n",
    "\n",
    "        X_train_t = X[X.index.isin(train_cv)]\n",
    "        y_train_t = y[y.index.isin(train_cv)]\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit(X_train_t['words_clean'].apply(lambda l: \" \".join(l)).values)\n",
    "        \n",
    "        result = []\n",
    "        for words, vec in X_train_t[['words_clean','wor2vec']].values:\n",
    "            weigh_vec = []\n",
    "            for w in words:\n",
    "                if w in vectorizer.vocabulary_:\n",
    "                    weigh_vec.append(vectorizer.vocabulary_[w])\n",
    "                else: \n",
    "                    weigh_vec.append(0)\n",
    "            if vec.shape[0] > 1:\n",
    "                result.append( np.average(vec, axis=0, weights=weigh_vec).reshape(1, -1) ) \n",
    "            else: \n",
    "                result.append( vec )\n",
    "\n",
    "        X_train_emb = np.concatenate(result)\n",
    "        \n",
    "        X_test_t = X[X.index.isin(test_cv)]\n",
    "        y_test_t = y[y.index.isin(test_cv)]\n",
    "        \n",
    "        result = []\n",
    "        for words, vec in X_test_t[['words_clean','wor2vec']].values:\n",
    "            weigh_vec = []\n",
    "            for w in words:\n",
    "                if w in vectorizer.vocabulary_:\n",
    "                    weigh_vec.append(vectorizer.vocabulary_[w])\n",
    "                else: \n",
    "                    weigh_vec.append(0)\n",
    "            if vec.shape[0] > 1:\n",
    "                result.append( np.average(vec, axis=0, weights=weigh_vec).reshape(1, -1) ) \n",
    "            else: \n",
    "                result.append( vec )\n",
    "                \n",
    "        X_test_emb = np.concatenate(result)\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train_emb, y_train_t)\n",
    "\n",
    "        y_pred = clf.predict(X_test_emb)\n",
    "        \n",
    "        confusion = confusion_matrix(y_test_t, y_pred)\n",
    "        c_matrix += confusion\n",
    "\n",
    "    #     TN, FP = confusion[0, 0], confusion[0, 1]\n",
    "    #     FN, TP = confusion[1, 0], confusion[1, 1]\n",
    "\n",
    "        results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "        results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "        results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "        results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": np.array(results['test_accuracy']),\n",
    "    #     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "    #     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "        \"F1 Score\":  np.array(results['test_f1']),\n",
    "        }\n",
    "\n",
    "#     print(c_matrix)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ec50f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = X_train_u[['sentiment_all', 'sentiment_avg', 'uniq_words',\n",
    "       'uniq_lemm', 'err', 'net', 'words_start_upper', 'words_full_upper',\n",
    "       'exclamation_marks', 'question_marks', 'upper_letters', 'chars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87831898",
   "metadata": {},
   "source": [
    "## Topics Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecfff58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f_pos = X_features.reset_index().join(X_pos_u.reset_index(drop=True), how=\"left\").set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd76287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "923a0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams   lr C1 Accuracy 0.515+-0.034 F1 Score 0.501+-0.076  0.515+-0.034 | 0.501+-0.076\n",
      "features lr C1 Accuracy 0.509+-0.032 F1 Score 0.454+-0.067  0.509+-0.032 | 0.454+-0.067\n",
      "pos      lr C1 Accuracy 0.561+-0.049 F1 Score 0.558+-0.049  0.561+-0.049 | 0.558+-0.049\n",
      "f + pos  lr C1 Accuracy 0.545+-0.059 F1 Score 0.549+-0.060  0.545+-0.059 | 0.549+-0.060\n",
      "word2vec lr C1 Accuracy 0.519+-0.039 F1 Score 0.527+-0.047  0.519+-0.039 | 0.527+-0.047\n"
     ]
    }
   ],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "clf_lr_01 = LogisticRegression(max_iter=5000, C=0.1, penalty='l2', solver='liblinear')\n",
    "\n",
    "for X_used, x_name in zip(\n",
    "    [X_ngram_u, X_features, X_pos_u, X_f_pos],\n",
    "    ['ngrams  ', 'features', 'pos     ', 'f + pos ']\n",
    "):\n",
    "    for clf_used, clf_name in zip(\n",
    "        [clf_lr_1],['lr C1']\n",
    "    ):\n",
    "        out = run_experiment(X_used, y_train_u, cv_fold, clf_used, 0.05)\n",
    "        print(\n",
    "            x_name, \n",
    "            clf_name,\n",
    "            f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "            f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "            f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    "        )\n",
    "\n",
    "out = run_experiment_w2v(X_w2v, y_train_u, cv_fold, clf_lr_1)\n",
    "print(\n",
    "    'word2vec lr C1',\n",
    "    f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "    f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "    f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed30078",
   "metadata": {},
   "source": [
    "## Random Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea823de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams   lr C1 Accuracy 0.528+-0.044 F1 Score 0.508+-0.056  0.528+-0.044 | 0.508+-0.056\n",
      "features lr C1 Accuracy 0.522+-0.029 F1 Score 0.466+-0.051  0.522+-0.029 | 0.466+-0.051\n",
      "pos      lr C1 Accuracy 0.563+-0.033 F1 Score 0.559+-0.046  0.563+-0.033 | 0.559+-0.046\n",
      "f + pos  lr C1 Accuracy 0.544+-0.043 F1 Score 0.540+-0.055  0.544+-0.043 | 0.540+-0.055\n",
      "word2vec lr C1 Accuracy 0.516+-0.023 F1 Score 0.519+-0.020  0.516+-0.023 | 0.519+-0.020\n"
     ]
    }
   ],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "clf_lr_01 = LogisticRegression(max_iter=5000, C=0.1, penalty='l2', solver='liblinear')\n",
    "        \n",
    "for X_used, x_name in zip(\n",
    "    [X_ngram_u, X_features, X_pos_u, X_f_pos],\n",
    "    ['ngrams  ', 'features', 'pos     ', 'f + pos ']\n",
    "):\n",
    "    for clf_used, clf_name in zip(\n",
    "        [clf_lr_1],['lr C1']\n",
    "    ):\n",
    "        out = run_experiment(X_used, y_train_u, cv_Kfold, clf_used, 0.03)\n",
    "        print(\n",
    "            x_name, \n",
    "            clf_name,\n",
    "            f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "            f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "            f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    "        )\n",
    "        \n",
    "out = run_experiment_w2v(X_w2v, y_train_u, cv_Kfold, clf_lr_1)\n",
    "print(\n",
    "    'word2vec lr C1',\n",
    "    f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "    f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "    f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f0eb9",
   "metadata": {},
   "source": [
    "## Use all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae319d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for X_used, x_name in zip(\n",
    "    [X_ngram_u, X_features, X_pos_u, X_f_pos],\n",
    "    ['ngrams  ', 'features', 'pos     ', 'f + pos ']\n",
    "):\n",
    "    \n",
    "    col_keep = []\n",
    "    for c in X_used.columns:\n",
    "        min_v =X_used[c].values.min()\n",
    "        max_v = X_used[c].values.max()\n",
    "\n",
    "        if min_v < max_v:\n",
    "            r = scipy.stats.pearsonr(X_used[c].values, y_train_u)[0]\n",
    "            if ~np.isnan(r) and r > 0.05:\n",
    "                col_keep.append(c)\n",
    "                    \n",
    "    results = cross_validate(estimator=clf_lr_1,\n",
    "                           X=X_used[col_keep],\n",
    "                           y=y_train_u,\n",
    "                           cv=cv_fold_i, #10,\n",
    "                           scoring=scoring,\n",
    "                           return_train_score=True)\n",
    "    print(\n",
    "        x_name, \n",
    "        'lr C1',\n",
    "        f'Accuracy {results[\"test_accuracy\"].mean():.3f}+-{results[\"test_accuracy\"].std():.3f}',\n",
    "        f'F1 Score {results[\"test_f1\"].mean():.3f}+-{results[\"test_f1\"].std():.3f}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ea9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for X_used, x_name in zip(\n",
    "    [X_ngram_u, X_features, X_pos_u, X_f_pos],\n",
    "    ['ngrams  ', 'features', 'pos     ', 'f + pos ']\n",
    "):\n",
    "    \n",
    "    col_keep = []\n",
    "    for c in X_used.columns:\n",
    "        min_v =X_used[c].values.min()\n",
    "        max_v = X_used[c].values.max()\n",
    "\n",
    "        if min_v < max_v:\n",
    "            r = scipy.stats.pearsonr(X_used[c].values, y_train_u)[0]\n",
    "            if ~np.isnan(r) and r > 0.05:\n",
    "                col_keep.append(c)\n",
    "                    \n",
    "    results = cross_validate(estimator=clf_lr_1,\n",
    "                           X=X_used[col_keep],\n",
    "                           y=y_train_u,\n",
    "                           cv=cv_Kfold_i, #10,\n",
    "                           scoring=scoring,\n",
    "                           return_train_score=True)\n",
    "    print(\n",
    "        x_name, \n",
    "        'lr C1',\n",
    "        f'Accuracy {results[\"test_accuracy\"].mean():.3f}+-{results[\"test_accuracy\"].std():.3f}',\n",
    "        f'F1 Score {results[\"test_f1\"].mean():.3f}+-{results[\"test_f1\"].std():.3f}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb0bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
