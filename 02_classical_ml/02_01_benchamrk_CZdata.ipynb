{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb3587c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
    ")\n",
    "\n",
    "import nltk\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from sklearn.base import clone as sklearn_clone\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "181a1d39-8608-42a4-bd81-cae872c7d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDERSAMPLING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148d9d1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e578f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styl = pd.read_parquet('../datasets/used_data/02_classical_ml/02_01_benchmark_styllometric_features.parquet')\n",
    "df_pos = pd.read_parquet('../datasets/used_data/02_classical_ml/02_02_benchmark_POS_ngrams.parquet')\n",
    "df_ngram = pd.read_parquet('../datasets/used_data/02_classical_ml/02_03_benchmark_words_ngrams.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a25689c-b8ad-4f22-a2cd-7582b90b060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2409, 28) (2409, 4650) (2409, 1174)\n"
     ]
    }
   ],
   "source": [
    "print(df_styl.shape, df_pos.shape, df_ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f170b532-6dc2-4d45-bf76-b9d826eca059",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_styl['assestment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ae97f2f-5d81-4c7b-a388-b011d3400fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styl.pop('assestment');\n",
    "df_pos.pop('assestment');\n",
    "df_ngram.pop('assestment');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20c751",
   "metadata": {},
   "source": [
    "## Make balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb5343ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_0 = y_train.value_counts()[0]\n",
    "n_1 = y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00c7b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lower = y_train.value_counts().min()\n",
    "n_upper = y_train.value_counts().max()\n",
    "\n",
    "np.random.seed(111)\n",
    "\n",
    "if UNDERSAMPLING:\n",
    "    # undersampling    \n",
    "    index_0 = np.random.choice(y_train[y_train==0].index, n_lower, replace=False)\n",
    "    index_1 = np.random.choice(y_train[y_train==1].index, n_lower, replace=False)\n",
    "\n",
    "    y_train_u = y_train.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    \n",
    "    X_train_u = df_styl.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_pos_u = df_pos.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_ngram_u = df_ngram.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "else:\n",
    "    # oversampling\n",
    "    if n_0 < n_1:\n",
    "        index_0 = np.random.choice(y_train[y_train==0].index, n_1, replace=True)\n",
    "        index_1 = np.random.choice(y_train[y_train==1].index, n_1, replace=False)\n",
    "    else:\n",
    "        index_0 = np.random.choice(y_train[y_train==0].index, n_0, replace=False)\n",
    "        index_1 = np.random.choice(y_train[y_train==1].index, n_0, replace=True)\n",
    "\n",
    "    y_train_u = y_train.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    \n",
    "    X_train_u = df_styl.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_pos_u = df_pos.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()\n",
    "    X_ngram_u = df_ngram.iloc[ index_0.tolist()+index_1.tolist() ].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c34bd",
   "metadata": {},
   "source": [
    "## CV creation\n",
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74ee952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_topic_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e128f7fe-2aba-4011-9568-96f7ec4c141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = X_ngram_u['TEXT_WORD'].str.split(' ').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1756bbd3-da5d-4db9-b01e-2da87e2328e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ngram_u.pop('TEXT_WORD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a02f856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1296/1296 [00:00<00:00, 9512.89it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(words)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in words]\n",
    "\n",
    "\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = ideal_topic_num, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   random_state=111,\n",
    "                                   workers = 7)\n",
    "\n",
    "topics = []\n",
    "\n",
    "for line in tqdm(words):\n",
    "    line_bow = dictionary.doc2bow(line)\n",
    "    doc_lda = lda_model[line_bow]\n",
    "    \n",
    "    topics.append( max(doc_lda, key=lambda x:x[1])[0] )\n",
    "\n",
    "# X_train_u['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd65141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.020*\"milion\" + 0.016*\"być\" + 0.013*\"polska\" + 0.008*\"rok\" + 0.007*\"budżet\"\n",
      "1 0.016*\"być\" + 0.009*\"rok\" + 0.009*\"prezydent\" + 0.007*\"kraj\" + 0.007*\"europa\"\n",
      "2 0.022*\"miliard\" + 0.021*\"polska\" + 0.011*\"pkb\" + 0.010*\"rok\" + 0.010*\"wzrost\"\n",
      "3 0.012*\"polska\" + 0.010*\"miejsce\" + 0.009*\"dziecko\" + 0.007*\"europa\" + 0.006*\"milion\"\n",
      "4 0.009*\"polski\" + 0.008*\"kaczyński\" + 0.008*\"rok\" + 0.007*\"ustawa\" + 0.007*\"rząd\"\n",
      "5 0.010*\"the\" + 0.009*\"kraj\" + 0.008*\"polska\" + 0.007*\"osoba\" + 0.007*\"europejski\"\n",
      "6 0.015*\"rok\" + 0.009*\"polska\" + 0.008*\"europejski\" + 0.007*\"rząd\" + 0.007*\"procent\"\n",
      "7 0.022*\"być\" + 0.012*\"rok\" + 0.012*\"procent\" + 0.009*\"milion\" + 0.007*\"złoty\"\n",
      "8 0.013*\"rok\" + 0.013*\"ustawa\" + 0.012*\"milion\" + 0.011*\"polska\" + 0.009*\"projekt\"\n",
      "9 0.016*\"europejski\" + 0.016*\"unia\" + 0.013*\"tysiąc\" + 0.010*\"polska\" + 0.009*\"państwo\"\n"
     ]
    }
   ],
   "source": [
    "x = lda_model.show_topics(num_topics=ideal_topic_num, num_words=5)\n",
    "\n",
    "for topic,word in x:\n",
    "    print(topic, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9351146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>assestment</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "assestment   0   1\n",
       "topic             \n",
       "0           60  79\n",
       "1           64  49\n",
       "2           89  80\n",
       "3           42  41\n",
       "4           70  54\n",
       "5           50  66\n",
       "6           73  64\n",
       "7           60  74\n",
       "8           94  82\n",
       "9           46  59"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_u_topics = pd.DataFrame(y_train_u.copy())\n",
    "y_train_u_topics['topic'] = topics\n",
    "y_train_u_topics['n'] = 1\n",
    "y_train_u_topics.groupby(['topic', 'assestment']).sum().reset_index().pivot(index='topic',columns='assestment',values='n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e17e0a",
   "metadata": {},
   "source": [
    "### Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8829acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fold = []\n",
    "cv_fold_i = []\n",
    "\n",
    "for i in y_train_u_topics['topic'].unique().reshape(10,-1):\n",
    "    train_cv = X_train_u.index[ ~np.isin(y_train_u_topics[\"topic\"], i) ].values\n",
    "    test_cv = X_train_u.index[ np.isin(y_train_u_topics[\"topic\"], i) ].values\n",
    "    \n",
    "    # train_cv_i = X_train_u.reset_index().index[ ~np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    # test_cv_i = X_train_u.reset_index().index[ np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    \n",
    "    cv_fold.append( [train_cv, test_cv])\n",
    "    # cv_fold_i.append( [train_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bec90100",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "kf.get_n_splits(X_train_u)\n",
    "\n",
    "cv_Kfold = []\n",
    "cv_Kfold_i = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_u):\n",
    "    train_cv = X_train_u.iloc[ train_index, : ].index.values\n",
    "    test_cv = X_train_u.iloc[ test_index, : ].index.values\n",
    "\n",
    "    # train_cv_i= X_train_u.reset_index().iloc[ train_index, : ].index.values\n",
    "    # test_cv_i = X_train_u.reset_index().iloc[ test_index, : ].index.values\n",
    "    \n",
    "    cv_Kfold.append( [train_cv, test_cv])\n",
    "    # cv_Kfold_i.append( [train_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0f426",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ff6e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, y, cv, clf_org, r_min=0.05):\n",
    "\n",
    "    results = {\n",
    "        'test_accuracy' : [],\n",
    "        'test_precision' : [],\n",
    "        'test_recall' : [],\n",
    "        'test_f1' : []\n",
    "    }\n",
    "\n",
    "    c_matrix = np.zeros((2,2))\n",
    "\n",
    "    for train_cv, test_cv in cv:\n",
    "        clf = sklearn_clone(clf_org)\n",
    "        \n",
    "        X_train_t = X[X.index.isin(train_cv)]\n",
    "        y_train_t = y[y.index.isin(train_cv)]\n",
    "\n",
    "        # keep only columns with corr > 0.05\n",
    "        if r_min>0:\n",
    "            col_keep = []\n",
    "            for c in X_train_t.columns:\n",
    "                min_v =X_train_t[c].values.min()\n",
    "                max_v = X_train_t[c].values.max()\n",
    "    \n",
    "                if min_v < max_v:\n",
    "                    r = scipy.stats.pearsonr(X_train_t[c].values, y_train_t)[0]\n",
    "                    if ~np.isnan(r) and r > r_min:\n",
    "                        col_keep.append(c)\n",
    "            \n",
    "            if len(col_keep) == 0:\n",
    "                print('No values returned')\n",
    "        \n",
    "            X_train_t = X_train_t[col_keep]\n",
    "\n",
    "\n",
    "        X_test_t = X[X.index.isin(test_cv)]\n",
    "        y_test_t = y[y.index.isin(test_cv)]\n",
    "        \n",
    "        if r_min>0:\n",
    "            X_test_t = X_test_t[col_keep]\n",
    "\n",
    "        clf.fit(X_train_t, y_train_t)\n",
    "\n",
    "        y_pred = clf.predict(X_test_t)\n",
    "\n",
    "        confusion = confusion_matrix(y_test_t, y_pred)\n",
    "        c_matrix += confusion\n",
    "\n",
    "    #     TN, FP = confusion[0, 0], confusion[0, 1]\n",
    "    #     FN, TP = confusion[1, 0], confusion[1, 1]\n",
    "\n",
    "        results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "        results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "        results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "        results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": np.array(results['test_accuracy']),\n",
    "    #     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "    #     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "        \"F1 Score\":  np.array(results['test_f1']),\n",
    "        }\n",
    "\n",
    "#     print(c_matrix)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87831898",
   "metadata": {},
   "source": [
    "## Topics Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd76287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0310f565-87d2-41a2-8d35-644c848cfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "clf_lr_01 = LogisticRegression(max_iter=5000, C=0.1, penalty='l2', solver='liblinear')\n",
    "clf_rf = RandomForestClassifier(random_state=111, max_depth=5)\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "923a0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams   lr C1 Accuracy 0.540+-0.038 F1 Score 0.432+-0.082  0.540+-0.038 | 0.432+-0.082\n",
      "features lr C1 Accuracy 0.509+-0.042 F1 Score 0.512+-0.054  0.509+-0.042 | 0.512+-0.054\n",
      "pos      lr C1 Accuracy 0.544+-0.051 F1 Score 0.526+-0.048  0.544+-0.051 | 0.526+-0.048\n",
      "\n",
      "ngrams   rf d5 Accuracy 0.522+-0.039 F1 Score 0.379+-0.122  0.522+-0.039 | 0.379+-0.122\n",
      "features rf d5 Accuracy 0.466+-0.035 F1 Score 0.492+-0.055  0.466+-0.035 | 0.492+-0.055\n",
      "pos      rf d5 Accuracy 0.528+-0.044 F1 Score 0.452+-0.037  0.528+-0.044 | 0.452+-0.037\n",
      "\n",
      "ngrams   xgb   Accuracy 0.516+-0.025 F1 Score 0.384+-0.108  0.516+-0.025 | 0.384+-0.108\n",
      "features xgb   Accuracy 0.479+-0.039 F1 Score 0.474+-0.039  0.479+-0.039 | 0.474+-0.039\n",
      "pos      xgb   Accuracy 0.494+-0.052 F1 Score 0.454+-0.048  0.494+-0.052 | 0.454+-0.048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_used, clf_name in zip(\n",
    "    [clf_lr_1, clf_rf, clf_xgb],['lr C1', 'rf d5', 'xgb  ']\n",
    "):\n",
    "        \n",
    "    for X_used, x_name in zip(\n",
    "        [X_ngram_u, X_train_u, X_pos_u],\n",
    "        ['ngrams  ', 'features', 'pos     ']\n",
    "    ):\n",
    "        out = run_experiment(X_used, y_train_u, cv_fold, clf_used, 0.05)\n",
    "        print(\n",
    "            x_name, \n",
    "            clf_name,\n",
    "            f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "            f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "            f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    "        )\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed30078",
   "metadata": {},
   "source": [
    "## Random Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea823de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams   lr C1 Accuracy 0.560+-0.045 F1 Score 0.488+-0.055  0.560+-0.045 | 0.488+-0.055\n",
      "features lr C1 Accuracy 0.524+-0.052 F1 Score 0.519+-0.059  0.524+-0.052 | 0.519+-0.059\n",
      "pos      lr C1 Accuracy 0.532+-0.037 F1 Score 0.508+-0.047  0.532+-0.037 | 0.508+-0.047\n",
      "\n",
      "ngrams   rf d5 Accuracy 0.540+-0.030 F1 Score 0.438+-0.048  0.540+-0.030 | 0.438+-0.048\n",
      "features rf d5 Accuracy 0.508+-0.069 F1 Score 0.528+-0.057  0.508+-0.069 | 0.528+-0.057\n",
      "pos      rf d5 Accuracy 0.532+-0.045 F1 Score 0.443+-0.047  0.532+-0.045 | 0.443+-0.047\n",
      "\n",
      "ngrams   xgb   Accuracy 0.511+-0.051 F1 Score 0.463+-0.060  0.511+-0.051 | 0.463+-0.060\n",
      "features xgb   Accuracy 0.505+-0.049 F1 Score 0.498+-0.039  0.505+-0.049 | 0.498+-0.039\n",
      "pos      xgb   Accuracy 0.531+-0.035 F1 Score 0.496+-0.047  0.531+-0.035 | 0.496+-0.047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_used, clf_name in zip(\n",
    "    [clf_lr_1, clf_rf, clf_xgb],['lr C1', 'rf d5', 'xgb  ']\n",
    "):\n",
    "        \n",
    "        \n",
    "    for X_used, x_name in zip(\n",
    "        [X_ngram_u, X_train_u, X_pos_u],\n",
    "        ['ngrams  ', 'features', 'pos     ']\n",
    "    ):\n",
    "        out = run_experiment(X_used, y_train_u, cv_Kfold, clf_used, 0.03)\n",
    "        print(\n",
    "            x_name, \n",
    "            clf_name,\n",
    "            f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "            f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "            f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    "        )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb0bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
