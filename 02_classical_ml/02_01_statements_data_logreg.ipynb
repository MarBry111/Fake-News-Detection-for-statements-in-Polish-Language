{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3587c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "import nltk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
    ")\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.base import clone as sklearn_clone\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from helpers.model import (\n",
    "    balance_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148d9d1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e578f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styl = pd.read_parquet('../datasets/used_data/02_classical_ml/03_01_statements_styllometric_features.parquet')\n",
    "df_pos = pd.read_parquet('../datasets/used_data/02_classical_ml/03_02_statements_POS_ngrams.parquet')\n",
    "df_ngram = pd.read_parquet('../datasets/used_data/02_classical_ml/03_03_statements_words_ngrams.parquet')\n",
    "\n",
    "with open('../datasets/used_data/02_classical_ml/03_04_statements_herbert.npy', 'rb') as f:\n",
    "    df_herbert = pd.DataFrame(np.load(f))\n",
    "\n",
    "with open('../datasets/used_data/02_classical_ml/03_05_statements_roberta.npy', 'rb') as f:\n",
    "    df_roberta = pd.DataFrame(np.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a25689c-b8ad-4f22-a2cd-7582b90b060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6529, 30) (6529, 2647) (6529, 2771) (6529, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(df_styl.shape, df_pos.shape, df_ngram.shape, df_herbert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f170b532-6dc2-4d45-bf76-b9d826eca059",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_styl['assestment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a75d7c2-0507-4735-9353-1345233c5073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assestment\n",
       "1    3434\n",
       "0    3095\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae97f2f-5d81-4c7b-a388-b011d3400fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styl.pop('assestment');\n",
    "df_pos.pop('assestment');\n",
    "df_ngram.pop('assestment');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20c751",
   "metadata": {},
   "source": [
    "## Make balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5343ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_u = df_styl\n",
    "X_pos_u = df_pos \n",
    "X_ngram_u = df_ngram\n",
    "X_herbert_u = df_herbert\n",
    "X_roberta_u = df_roberta\n",
    "\n",
    "y_train_u = y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e696f3d-a547-4694-aca5-4ebe6ae3fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = X_ngram_u['TEXT_WORD'].str.split(' ').values\n",
    "X_ngram_u.pop('TEXT_WORD');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c34bd",
   "metadata": {},
   "source": [
    "## CV creation\n",
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74ee952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_topic_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a02f856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6529/6529 [00:01<00:00, 5802.53it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(words)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in words]\n",
    "\n",
    "\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = ideal_topic_num, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   random_state=111,\n",
    "                                   workers = 7)\n",
    "\n",
    "topics = []\n",
    "\n",
    "for line in tqdm(words):\n",
    "    line_bow = dictionary.doc2bow(line)\n",
    "    doc_lda = lda_model[line_bow]\n",
    "    \n",
    "    topics.append( max(doc_lda, key=lambda x:x[1])[0] )\n",
    "\n",
    "# X_train_u['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd65141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.033*\"europejski\" + 0.021*\"unia\" + 0.014*\"komisja\" + 0.011*\"sprawa\" + 0.010*\"europa\"\n",
      "1 0.021*\"prawo\" + 0.014*\"trybunał\" + 0.013*\"ustawa\" + 0.013*\"konstytucja\" + 0.013*\"polski\"\n",
      "2 0.016*\"procent\" + 0.013*\"minister\" + 0.009*\"polak\" + 0.008*\"bezrobocie\" + 0.007*\"europejski\"\n",
      "3 0.018*\"państwo\" + 0.015*\"kraj\" + 0.015*\"budżet\" + 0.013*\"prezydent\" + 0.012*\"europejski\"\n",
      "4 0.016*\"wybory\" + 0.014*\"osoba\" + 0.012*\"rząd\" + 0.010*\"poseł\" + 0.010*\"sejm\"\n",
      "5 0.017*\"sędzia\" + 0.012*\"sąd\" + 0.010*\"trybunał\" + 0.009*\"konstytucyjny\" + 0.008*\"duży\"\n",
      "6 0.013*\"mówić\" + 0.013*\"miejsce\" + 0.010*\"osoba\" + 0.009*\"polak\" + 0.009*\"program\"\n",
      "7 0.021*\"procent\" + 0.021*\"pkb\" + 0.016*\"wzrost\" + 0.013*\"poziom\" + 0.011*\"wzrosnąć\"\n",
      "8 0.038*\"dziecko\" + 0.024*\"złoty\" + 0.012*\"warszawa\" + 0.012*\"chodzić\" + 0.012*\"miasto\"\n",
      "9 0.021*\"człowiek\" + 0.013*\"osoba\" + 0.012*\"kraj\" + 0.008*\"europejski\" + 0.008*\"mówić\"\n"
     ]
    }
   ],
   "source": [
    "x = lda_model.show_topics(num_topics=ideal_topic_num, num_words=5)\n",
    "\n",
    "for topic,word in x:\n",
    "    print(topic, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9351146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>assestment</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>345</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>355</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>241</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>284</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>347</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>353</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>281</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "assestment    0    1\n",
       "topic               \n",
       "0           255  335\n",
       "1           345  560\n",
       "2           355  268\n",
       "3           341  311\n",
       "4           293  330\n",
       "5           241  307\n",
       "6           284  372\n",
       "7           347  285\n",
       "8           353  315\n",
       "9           281  351"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_u_topics = pd.DataFrame(y_train_u.copy())\n",
    "y_train_u_topics['topic'] = topics\n",
    "y_train_u_topics['n'] = 1\n",
    "y_train_u_topics.groupby(['topic', 'assestment']).sum().reset_index().pivot(index='topic',columns='assestment',values='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43054ea4-ee02-445e-b6f7-6522025f50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = y_train_u_topics.groupby(['topic', 'assestment']).sum().reset_index().pivot(index='topic',columns='assestment',values='n')\n",
    "# df_plot[1] = -df_plot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5004c8d1-ef41-44f3-a74a-da83ee0f4af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transpose the DataFrame\n",
    "# df_plot = df_plot.transpose()\n",
    "\n",
    "# Plotting bidirectional bar plot\n",
    "fig, ax = plt.subplots()\n",
    "df_plot.plot(kind='barh', stacked=False, ax=ax)\n",
    "\n",
    "# Adjusting labels and legend\n",
    "ax.set_ylabel('Topic')\n",
    "ax.set_xlabel('Number of claims in given topic')\n",
    "# ax.set_title('Bidirectional Bar Plot')\n",
    "# ax.legend(title='Assessment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6435e1cb-7062-4911-893e-f05e29353090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../datasets/used_data/03_bert_like_models/02_topics.npy', 'wb') as f:\n",
    "#     np.save(f, np.array(topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e17e0a",
   "metadata": {},
   "source": [
    "### Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8829acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fold = []\n",
    "cv_fold_i = []\n",
    "\n",
    "for i in y_train_u_topics['topic'].unique().reshape(10,-1):\n",
    "    train_cv = X_train_u.index[ ~np.isin(y_train_u_topics[\"topic\"], i) ].values\n",
    "    test_cv = X_train_u.index[ np.isin(y_train_u_topics[\"topic\"], i) ].values\n",
    "    \n",
    "    # train_cv_i = X_train_u.reset_index().index[ ~np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    # test_cv_i = X_train_u.reset_index().index[ np.isin(X_train_u[\"topic\"], i) ].values\n",
    "    \n",
    "    cv_fold.append( [train_cv, test_cv])\n",
    "    # cv_fold_i.append( [train_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec90100",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=111)\n",
    "kf.get_n_splits(X_train_u)\n",
    "\n",
    "cv_Kfold = []\n",
    "cv_Kfold_i = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_u):\n",
    "    train_cv = X_train_u.iloc[ train_index, : ].index.values\n",
    "    test_cv = X_train_u.iloc[ test_index, : ].index.values\n",
    "\n",
    "    # train_cv_i= X_train_u.reset_index().iloc[ train_index, : ].index.values\n",
    "    # test_cv_i = X_train_u.reset_index().iloc[ test_index, : ].index.values\n",
    "    \n",
    "    cv_Kfold.append( [train_cv, test_cv])\n",
    "    # cv_Kfold_i.append( [train_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bfaec6d-b62d-4038-a719-b5fa237cb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../datasets/used_data/cv_fold.txt\", 'w') as fp:\n",
    "#     json.dump(cv_fold, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0f426",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ff6e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, y, cv, clf_org, r_min=0.05):\n",
    "\n",
    "    results = {\n",
    "        'test_accuracy' : [],\n",
    "        'test_precision' : [],\n",
    "        'test_recall' : [],\n",
    "        'test_f1' : [],\n",
    "        'col_keep' : []\n",
    "    }\n",
    "\n",
    "    c_matrix = np.zeros((2,2))\n",
    "\n",
    "    for train_cv, test_cv in cv:\n",
    "        clf = sklearn_clone(clf_org)\n",
    "        \n",
    "        X_train_t = X[X.index.isin(train_cv)]\n",
    "        y_train_t = y[y.index.isin(train_cv)]\n",
    "\n",
    "        # keep only columns with corr > 0.05\n",
    "        if r_min:\n",
    "            col_keep = []\n",
    "            for c in X_train_t.columns:\n",
    "                min_v =X_train_t[c].values.min()\n",
    "                max_v = X_train_t[c].values.max()\n",
    "    \n",
    "                if min_v < max_v:\n",
    "                    r = scipy.stats.pearsonr(X_train_t[c].values, y_train_t)[0]\n",
    "                    if ~np.isnan(r) and r > r_min:\n",
    "                        col_keep.append(c)\n",
    "            \n",
    "            if len(col_keep) == 0:\n",
    "                print('No values returned')\n",
    "        \n",
    "            X_train_t = X_train_t[col_keep]\n",
    "        else:\n",
    "            col_keep =  X_train_t.columns.values.tolist()\n",
    "\n",
    "\n",
    "        X_test_t = X[X.index.isin(test_cv)]\n",
    "        y_test_t = y[y.index.isin(test_cv)]\n",
    "        \n",
    "        if r_min:\n",
    "            X_test_t = X_test_t[col_keep]\n",
    "\n",
    "        clf.fit(X_train_t, y_train_t)\n",
    "\n",
    "        y_pred = clf.predict(X_test_t)\n",
    "\n",
    "        confusion = confusion_matrix(y_test_t, y_pred)\n",
    "        c_matrix += confusion\n",
    "\n",
    "    #     TN, FP = confusion[0, 0], confusion[0, 1]\n",
    "    #     FN, TP = confusion[1, 0], confusion[1, 1]\n",
    "\n",
    "        results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "        results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "        results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "        results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "        results['col_keep'].append( len(col_keep)) \n",
    "    \n",
    "    metrics = {\n",
    "        \"Accuracy\": np.array(results['test_accuracy']),\n",
    "        \"Precision\": np.array(results['test_precision']).mean(),\n",
    "        \"Recall\": np.array(results['test_recall']).mean(),\n",
    "        \"F1 Score\":  np.array(results['test_f1']),\n",
    "        \"Cols used\": np.array(results['col_keep']),\n",
    "        }\n",
    "\n",
    "#     print(c_matrix)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87831898",
   "metadata": {},
   "source": [
    "## Topics Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd76287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0310f565-87d2-41a2-8d35-644c848cfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "clf_lr_01 = LogisticRegression(max_iter=5000, C=0.1, penalty='l2', solver='liblinear')\n",
    "clf_rf = RandomForestClassifier(random_state=111, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "923a0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams  None lr C1 Accuracy 0.62+-0.02 F1 Score 0.67+-0.06 Cols used 2769+-0\n",
      "ngrams  0.03 lr C1 Accuracy 0.60+-0.02 F1 Score 0.62+-0.06 Cols used 162+-6\n",
      "features     lr C1 Accuracy 0.55+-0.03 F1 Score 0.62+-0.04 Cols used 29+-0\n",
      "pos     None lr C1 Accuracy 0.54+-0.03 F1 Score 0.60+-0.04 Cols used 2646+-0\n",
      "pos     0.03 lr C1 Accuracy 0.53+-0.02 F1 Score 0.59+-0.04 Cols used 70+-6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_used, clf_name in zip(\n",
    "    [\n",
    "        clf_lr_1, \n",
    "        # clf_rf, #clf_xgb\n",
    "    ],[\n",
    "        'lr C1', \n",
    "        # 'rf d5', #'xgb  '\n",
    "    ]\n",
    "):\n",
    "        \n",
    "    for X_used, x_name, r_min in zip(\n",
    "        # [X_ngram_u, X_train_u, X_pos_u, X_herbert_u],\n",
    "        # ['ngrams  ', 'features', 'pos     ', 'herbert '],\n",
    "        # [0.01, None, 0.01, None]\n",
    "        [X_ngram_u, \n",
    "         X_ngram_u, \n",
    "         # X_ngram_u, \n",
    "         # X_ngram_u, \n",
    "         X_train_u, \n",
    "         X_pos_u, \n",
    "         X_pos_u, \n",
    "         # X_pos_u, \n",
    "         # X_pos_u, \n",
    "         ],\n",
    "        ['ngrams  None', \n",
    "         # 'ngrams  0.01', \n",
    "         'ngrams  0.03', \n",
    "         # 'ngrams  0.05', \n",
    "         'features    ', \n",
    "         'pos     None', \n",
    "         # 'pos     0.01', \n",
    "         'pos     0.03', \n",
    "         # 'pos     0.05', \n",
    "        ],\n",
    "        [None, \n",
    "         # 0.01, \n",
    "         0.03,\n",
    "         # 0.05, \n",
    "         None, \n",
    "         None, \n",
    "         # 0.01, \n",
    "         0.03, \n",
    "         # 0.05, \n",
    "         ]\n",
    "    ):\n",
    "        out = run_experiment(X_used, y_train_u, cv_fold, clf_used, r_min)\n",
    "        print(\n",
    "            x_name, \n",
    "            clf_name,\n",
    "            f'Accuracy {out[\"Accuracy\"].mean():.2f}+-{out[\"Accuracy\"].std():.2f}',\n",
    "            f'F1 Score {out[\"F1 Score\"].mean():.2f}+-{out[\"F1 Score\"].std():.2f}',\n",
    "            f'Cols used {out[\"Cols used\"].mean().round(0):.0f}+-{out[\"Cols used\"].std().round(0):.0f}',\n",
    "            # f'Cols used {len(out[\"Cols used\"])}',\n",
    "            # f'\\n\\tPrecision {out[\"Precision\"].mean():.2f}+-{out[\"Precision\"].std():.2f}',\n",
    "            # f'\\n\\tRecall {out[\"Recall\"].mean():.2f}+-{out[\"Recall\"].std():.2f}',\n",
    "            # f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    "        )\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed30078",
   "metadata": {},
   "source": [
    "## Random Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "191ccf91-7937-44c5-bf2d-b7e30d422bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams  None lr C1 Accuracy 0.63+-0.02 F1 Score 0.68+-0.02 Cols used 2769+-0\n",
      "ngrams  0.03 lr C1 Accuracy 0.60+-0.02 F1 Score 0.63+-0.02 Cols used 161+-9\n",
      "features     lr C1 Accuracy 0.56+-0.02 F1 Score 0.63+-0.02 Cols used 29+-0\n",
      "pos     None lr C1 Accuracy 0.54+-0.01 F1 Score 0.61+-0.01 Cols used 2646+-0\n",
      "pos     0.03 lr C1 Accuracy 0.54+-0.01 F1 Score 0.60+-0.02 Cols used 73+-6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_used, clf_name in zip(\n",
    "    [\n",
    "        clf_lr_1, \n",
    "        # clf_rf, # clf_xgb\n",
    "    ],[\n",
    "        'lr C1', \n",
    "        # 'rf d5', # 'xgb  '\n",
    "    ]\n",
    "):\n",
    "        \n",
    "    for X_used, x_name, r_min in zip(\n",
    "        [X_ngram_u, \n",
    "         X_ngram_u, \n",
    "         # X_ngram_u, \n",
    "         # X_ngram_u, \n",
    "         X_train_u, \n",
    "         X_pos_u, \n",
    "         X_pos_u, \n",
    "         # X_pos_u, \n",
    "         # X_pos_u, \n",
    "         ],\n",
    "        ['ngrams  None', \n",
    "         # 'ngrams  0.01', \n",
    "         'ngrams  0.03', \n",
    "         # 'ngrams  0.05', \n",
    "         'features    ', \n",
    "         'pos     None', \n",
    "         # 'pos     0.01', \n",
    "         'pos     0.03', \n",
    "         # 'pos     0.05', \n",
    "        ],\n",
    "        [None, \n",
    "         # 0.01, \n",
    "         0.03,\n",
    "         # 0.05, \n",
    "         None, \n",
    "         None, \n",
    "         # 0.01, \n",
    "         0.03, \n",
    "         # 0.05, \n",
    "         ]\n",
    "    ):\n",
    "        out = run_experiment(X_used, y_train_u, cv_Kfold, clf_used, r_min)\n",
    "        print(\n",
    "            x_name, \n",
    "            clf_name,\n",
    "            f'Accuracy {out[\"Accuracy\"].mean():.2f}+-{out[\"Accuracy\"].std():.2f}',\n",
    "            f'F1 Score {out[\"F1 Score\"].mean():.2f}+-{out[\"F1 Score\"].std():.2f}',\n",
    "            f'Cols used {out[\"Cols used\"].mean().round(0):.0f}+-{out[\"Cols used\"].std().round(0):.0f}',\n",
    "            # f'Cols used {len(out[\"Cols used\"])}',\n",
    "            # f'\\n\\tPrecision {out[\"Precision\"].mean():.2f}+-{out[\"Precision\"].std():.2f}',\n",
    "            # f'\\n\\tRecall {out[\"Recall\"].mean():.2f}+-{out[\"Recall\"].std():.2f}',\n",
    "            # f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    "        )\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d53dea-83a7-4622-8b0f-ea0fae52b963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bca209a7-8bb2-4061-86f3-248cab3553bb",
   "metadata": {},
   "source": [
    "## XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a7c6b-d96e-4a62-8f32-77be5037d2c6",
   "metadata": {},
   "source": [
    "### Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3306237c-33ae-420a-8f07-57c712b7297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:22<00:00,  2.25s/it]\n"
     ]
    }
   ],
   "source": [
    "cv = cv_Kfold  \n",
    "X = X_ngram_u\n",
    "y = y_train_u\n",
    "r_min = 0.03 \n",
    "\n",
    "imp = []\n",
    "\n",
    "for train_cv, test_cv in tqdm(cv):\n",
    "    clf = sklearn_clone(clf_lr_1)\n",
    "    \n",
    "    X_train_t = X[X.index.isin(train_cv)]\n",
    "    y_train_t = y[y.index.isin(train_cv)]\n",
    "\n",
    "    # keep only columns with corr > 0.05\n",
    "    if r_min:\n",
    "        col_keep = []\n",
    "        for c in X_train_t.columns:\n",
    "            min_v =X_train_t[c].values.min()\n",
    "            max_v = X_train_t[c].values.max()\n",
    "\n",
    "            if min_v < max_v:\n",
    "                r = scipy.stats.pearsonr(X_train_t[c].values, y_train_t)[0]\n",
    "                if ~np.isnan(r) and r > r_min:\n",
    "                    col_keep.append(c)\n",
    "        \n",
    "        if len(col_keep) == 0:\n",
    "            print('No values returned')\n",
    "    \n",
    "        X_train_t = X_train_t[col_keep]\n",
    "    else:\n",
    "        col_keep =  X_train_t.columns.values.tolist()\n",
    "\n",
    "\n",
    "    X_test_t = X[X.index.isin(test_cv)]\n",
    "    y_test_t = y[y.index.isin(test_cv)]\n",
    "    \n",
    "    if r_min:\n",
    "        X_test_t = X_test_t[col_keep]\n",
    "\n",
    "    clf.fit(X_train_t, y_train_t)\n",
    "\n",
    "    y_pred = clf.predict(X_test_t)\n",
    "    \n",
    "    coefficients = clf.coef_[0]\n",
    "    imp.append({col_keep[i]: coefficients[i] for i in range(len(col_keep))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89b5f96a-c82f-4099-a2c1-6c76efa8a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66acbcb3-bc9c-4528-97ca-6d11d4569d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 286)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6808ce78-a3b1-4849-a032-0a06ec920062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wolność</th>\n",
       "      <th>wiedza</th>\n",
       "      <th>szkoda</th>\n",
       "      <th>sklep</th>\n",
       "      <th>wino</th>\n",
       "      <th>podwójny</th>\n",
       "      <th>wysiłek</th>\n",
       "      <th>środkowy</th>\n",
       "      <th>rodzaj</th>\n",
       "      <th>dzięki</th>\n",
       "      <th>...</th>\n",
       "      <th>media publiczny</th>\n",
       "      <th>walka</th>\n",
       "      <th>handel</th>\n",
       "      <th>chrześcijański</th>\n",
       "      <th>swoboda</th>\n",
       "      <th>stan</th>\n",
       "      <th>powód</th>\n",
       "      <th>olbrzymi</th>\n",
       "      <th>dopuszczać</th>\n",
       "      <th>poradzić</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.812422</td>\n",
       "      <td>0.481063</td>\n",
       "      <td>0.562142</td>\n",
       "      <td>0.422788</td>\n",
       "      <td>0.302558</td>\n",
       "      <td>0.264923</td>\n",
       "      <td>0.333691</td>\n",
       "      <td>0.201444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.880987</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695817</td>\n",
       "      <td>0.640148</td>\n",
       "      <td>0.492264</td>\n",
       "      <td>0.317685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.218167</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.430036</td>\n",
       "      <td>0.297405</td>\n",
       "      <td>0.302983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    wolność    wiedza    szkoda     sklep      wino  podwójny   wysiłek  \\\n",
       "0  0.812422  0.481063  0.562142  0.422788  0.302558  0.264923  0.333691   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "5       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "6       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "7       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "8       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "9       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   środkowy    rodzaj    dzięki  ...  media publiczny     walka    handel  \\\n",
       "0  0.201444       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "1       NaN  0.715756  0.880987  ...              NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "5       NaN       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "6       NaN       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "7       NaN       NaN       NaN  ...         0.345357       NaN       NaN   \n",
       "8       NaN       NaN       NaN  ...              NaN  0.695817  0.640148   \n",
       "9       NaN       NaN       NaN  ...              NaN       NaN       NaN   \n",
       "\n",
       "   chrześcijański   swoboda      stan     powód  olbrzymi  dopuszczać  \\\n",
       "0             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "1             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "2             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "3             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "4             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "5             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "6             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "7             NaN       NaN       NaN       NaN       NaN         NaN   \n",
       "8        0.492264  0.317685       NaN       NaN       NaN         NaN   \n",
       "9             NaN       NaN  1.218167  0.839667  0.430036    0.297405   \n",
       "\n",
       "   poradzić  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "5       NaN  \n",
       "6       NaN  \n",
       "7       NaN  \n",
       "8       NaN  \n",
       "9  0.302983  \n",
       "\n",
       "[10 rows x 72 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp.loc[ :, df_imp.notna().sum() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7b33d85-379f-41a1-9523-178fd342abae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prawo</th>\n",
       "      <th>człowiek</th>\n",
       "      <th>chcieć</th>\n",
       "      <th>sędzia</th>\n",
       "      <th>móc</th>\n",
       "      <th>władza</th>\n",
       "      <th>strona</th>\n",
       "      <th>polityka</th>\n",
       "      <th>wiedzieć</th>\n",
       "      <th>polityczny</th>\n",
       "      <th>...</th>\n",
       "      <th>elita</th>\n",
       "      <th>widz</th>\n",
       "      <th>bić</th>\n",
       "      <th>wizja</th>\n",
       "      <th>czyn</th>\n",
       "      <th>komisja europejski</th>\n",
       "      <th>wymiar sprawiedliwość</th>\n",
       "      <th>puszczać białowieski</th>\n",
       "      <th>większość parlamentarny</th>\n",
       "      <th>trybunał sprawiedliwość</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.253462</td>\n",
       "      <td>1.197414</td>\n",
       "      <td>1.867369</td>\n",
       "      <td>1.409156</td>\n",
       "      <td>1.690625</td>\n",
       "      <td>1.365179</td>\n",
       "      <td>1.167953</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>1.516921</td>\n",
       "      <td>1.168873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269766</td>\n",
       "      <td>1.272461</td>\n",
       "      <td>1.251635</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>1.933548</td>\n",
       "      <td>0.867741</td>\n",
       "      <td>0.593820</td>\n",
       "      <td>0.428195</td>\n",
       "      <td>0.340647</td>\n",
       "      <td>0.344886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.016170</td>\n",
       "      <td>1.115983</td>\n",
       "      <td>2.160322</td>\n",
       "      <td>1.613345</td>\n",
       "      <td>1.499016</td>\n",
       "      <td>1.136800</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.298977</td>\n",
       "      <td>1.526211</td>\n",
       "      <td>1.188712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>1.314346</td>\n",
       "      <td>1.326978</td>\n",
       "      <td>0.773066</td>\n",
       "      <td>1.612178</td>\n",
       "      <td>0.971238</td>\n",
       "      <td>0.690369</td>\n",
       "      <td>0.472487</td>\n",
       "      <td>0.342916</td>\n",
       "      <td>0.304017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.076536</td>\n",
       "      <td>1.132917</td>\n",
       "      <td>2.193289</td>\n",
       "      <td>1.559256</td>\n",
       "      <td>1.645693</td>\n",
       "      <td>1.228836</td>\n",
       "      <td>1.299393</td>\n",
       "      <td>1.153183</td>\n",
       "      <td>1.432592</td>\n",
       "      <td>1.265293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264759</td>\n",
       "      <td>1.111586</td>\n",
       "      <td>1.121597</td>\n",
       "      <td>0.830593</td>\n",
       "      <td>2.017025</td>\n",
       "      <td>0.916491</td>\n",
       "      <td>0.794350</td>\n",
       "      <td>0.406934</td>\n",
       "      <td>0.315390</td>\n",
       "      <td>0.307606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.187157</td>\n",
       "      <td>1.128933</td>\n",
       "      <td>1.904590</td>\n",
       "      <td>1.405387</td>\n",
       "      <td>1.764866</td>\n",
       "      <td>1.142098</td>\n",
       "      <td>1.323613</td>\n",
       "      <td>1.266193</td>\n",
       "      <td>1.444064</td>\n",
       "      <td>1.303130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288251</td>\n",
       "      <td>1.316702</td>\n",
       "      <td>1.068350</td>\n",
       "      <td>0.617327</td>\n",
       "      <td>1.770220</td>\n",
       "      <td>1.062317</td>\n",
       "      <td>0.729599</td>\n",
       "      <td>0.489377</td>\n",
       "      <td>0.305346</td>\n",
       "      <td>0.373521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.947331</td>\n",
       "      <td>1.035833</td>\n",
       "      <td>2.215438</td>\n",
       "      <td>1.312292</td>\n",
       "      <td>1.577328</td>\n",
       "      <td>0.945842</td>\n",
       "      <td>1.077641</td>\n",
       "      <td>1.255479</td>\n",
       "      <td>1.919601</td>\n",
       "      <td>1.399641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257317</td>\n",
       "      <td>1.523159</td>\n",
       "      <td>1.282533</td>\n",
       "      <td>0.641318</td>\n",
       "      <td>1.862819</td>\n",
       "      <td>1.013743</td>\n",
       "      <td>0.757560</td>\n",
       "      <td>0.335393</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.354311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.996378</td>\n",
       "      <td>1.125737</td>\n",
       "      <td>1.980032</td>\n",
       "      <td>1.413024</td>\n",
       "      <td>1.597007</td>\n",
       "      <td>0.902896</td>\n",
       "      <td>1.239230</td>\n",
       "      <td>1.276131</td>\n",
       "      <td>1.172722</td>\n",
       "      <td>1.380186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293838</td>\n",
       "      <td>1.228967</td>\n",
       "      <td>1.252611</td>\n",
       "      <td>0.709910</td>\n",
       "      <td>2.086323</td>\n",
       "      <td>0.869704</td>\n",
       "      <td>0.731253</td>\n",
       "      <td>0.425909</td>\n",
       "      <td>0.253131</td>\n",
       "      <td>0.371373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.052967</td>\n",
       "      <td>1.022027</td>\n",
       "      <td>2.237600</td>\n",
       "      <td>1.229258</td>\n",
       "      <td>1.911428</td>\n",
       "      <td>1.118328</td>\n",
       "      <td>1.167489</td>\n",
       "      <td>1.220242</td>\n",
       "      <td>1.276058</td>\n",
       "      <td>1.309019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292001</td>\n",
       "      <td>1.412090</td>\n",
       "      <td>1.437931</td>\n",
       "      <td>0.648118</td>\n",
       "      <td>1.869926</td>\n",
       "      <td>0.855497</td>\n",
       "      <td>0.707682</td>\n",
       "      <td>0.458002</td>\n",
       "      <td>0.219393</td>\n",
       "      <td>0.330449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.017594</td>\n",
       "      <td>1.154998</td>\n",
       "      <td>1.964900</td>\n",
       "      <td>1.789792</td>\n",
       "      <td>1.603108</td>\n",
       "      <td>1.125208</td>\n",
       "      <td>1.297843</td>\n",
       "      <td>1.353976</td>\n",
       "      <td>1.348181</td>\n",
       "      <td>1.054127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218859</td>\n",
       "      <td>1.281099</td>\n",
       "      <td>1.446196</td>\n",
       "      <td>0.862072</td>\n",
       "      <td>1.938236</td>\n",
       "      <td>0.877728</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.376909</td>\n",
       "      <td>0.325724</td>\n",
       "      <td>0.324352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.832731</td>\n",
       "      <td>1.087674</td>\n",
       "      <td>2.103566</td>\n",
       "      <td>1.154080</td>\n",
       "      <td>1.710795</td>\n",
       "      <td>1.311927</td>\n",
       "      <td>1.164877</td>\n",
       "      <td>1.293918</td>\n",
       "      <td>1.506087</td>\n",
       "      <td>1.290934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253520</td>\n",
       "      <td>1.201084</td>\n",
       "      <td>1.297652</td>\n",
       "      <td>0.695910</td>\n",
       "      <td>1.848720</td>\n",
       "      <td>1.054314</td>\n",
       "      <td>0.782367</td>\n",
       "      <td>0.388190</td>\n",
       "      <td>0.284725</td>\n",
       "      <td>0.359972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.883553</td>\n",
       "      <td>1.095723</td>\n",
       "      <td>2.099511</td>\n",
       "      <td>1.544827</td>\n",
       "      <td>1.667720</td>\n",
       "      <td>1.269060</td>\n",
       "      <td>1.132451</td>\n",
       "      <td>1.397986</td>\n",
       "      <td>1.448266</td>\n",
       "      <td>1.173794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240022</td>\n",
       "      <td>1.366785</td>\n",
       "      <td>1.345136</td>\n",
       "      <td>0.668304</td>\n",
       "      <td>1.858809</td>\n",
       "      <td>0.934490</td>\n",
       "      <td>0.735189</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.336988</td>\n",
       "      <td>0.317546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prawo  człowiek    chcieć    sędzia       móc    władza    strona  \\\n",
       "0  2.253462  1.197414  1.867369  1.409156  1.690625  1.365179  1.167953   \n",
       "1  2.016170  1.115983  2.160322  1.613345  1.499016  1.136800  0.993076   \n",
       "2  2.076536  1.132917  2.193289  1.559256  1.645693  1.228836  1.299393   \n",
       "3  2.187157  1.128933  1.904590  1.405387  1.764866  1.142098  1.323613   \n",
       "4  1.947331  1.035833  2.215438  1.312292  1.577328  0.945842  1.077641   \n",
       "5  1.996378  1.125737  1.980032  1.413024  1.597007  0.902896  1.239230   \n",
       "6  2.052967  1.022027  2.237600  1.229258  1.911428  1.118328  1.167489   \n",
       "7  2.017594  1.154998  1.964900  1.789792  1.603108  1.125208  1.297843   \n",
       "8  1.832731  1.087674  2.103566  1.154080  1.710795  1.311927  1.164877   \n",
       "9  1.883553  1.095723  2.099511  1.544827  1.667720  1.269060  1.132451   \n",
       "\n",
       "   polityka  wiedzieć  polityczny  ...     elita      widz       bić  \\\n",
       "0  0.909836  1.516921    1.168873  ...  0.269766  1.272461  1.251635   \n",
       "1  1.298977  1.526211    1.188712  ...  0.260437  1.314346  1.326978   \n",
       "2  1.153183  1.432592    1.265293  ...  0.264759  1.111586  1.121597   \n",
       "3  1.266193  1.444064    1.303130  ...  0.288251  1.316702  1.068350   \n",
       "4  1.255479  1.919601    1.399641  ...  0.257317  1.523159  1.282533   \n",
       "5  1.276131  1.172722    1.380186  ...  0.293838  1.228967  1.252611   \n",
       "6  1.220242  1.276058    1.309019  ...  0.292001  1.412090  1.437931   \n",
       "7  1.353976  1.348181    1.054127  ...  0.218859  1.281099  1.446196   \n",
       "8  1.293918  1.506087    1.290934  ...  0.253520  1.201084  1.297652   \n",
       "9  1.397986  1.448266    1.173794  ...  0.240022  1.366785  1.345136   \n",
       "\n",
       "      wizja      czyn  komisja europejski  wymiar sprawiedliwość  \\\n",
       "0  0.704767  1.933548            0.867741               0.593820   \n",
       "1  0.773066  1.612178            0.971238               0.690369   \n",
       "2  0.830593  2.017025            0.916491               0.794350   \n",
       "3  0.617327  1.770220            1.062317               0.729599   \n",
       "4  0.641318  1.862819            1.013743               0.757560   \n",
       "5  0.709910  2.086323            0.869704               0.731253   \n",
       "6  0.648118  1.869926            0.855497               0.707682   \n",
       "7  0.862072  1.938236            0.877728               0.611940   \n",
       "8  0.695910  1.848720            1.054314               0.782367   \n",
       "9  0.668304  1.858809            0.934490               0.735189   \n",
       "\n",
       "   puszczać białowieski  większość parlamentarny  trybunał sprawiedliwość  \n",
       "0              0.428195                 0.340647                 0.344886  \n",
       "1              0.472487                 0.342916                 0.304017  \n",
       "2              0.406934                 0.315390                 0.307606  \n",
       "3              0.489377                 0.305346                 0.373521  \n",
       "4              0.335393                 0.342496                 0.354311  \n",
       "5              0.425909                 0.253131                 0.371373  \n",
       "6              0.458002                 0.219393                 0.330449  \n",
       "7              0.376909                 0.325724                 0.324352  \n",
       "8              0.388190                 0.284725                 0.359972  \n",
       "9              0.406756                 0.336988                 0.317546  \n",
       "\n",
       "[10 rows x 78 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp.loc[ :, df_imp.notna().sum() == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a93ce6d-3fe0-4201-8d4a-336562b70433",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv_Kfold  \n",
    "X = X_ngram_u\n",
    "y = y_train_u\n",
    "r_min = 0.03 \n",
    "\n",
    "imp_random = []\n",
    "\n",
    "train_cv, test_cv = cv[0]\n",
    "clf = sklearn_clone(clf_lr_1)\n",
    "\n",
    "X_train_t = X[X.index.isin(train_cv)]\n",
    "y_train_t = y[y.index.isin(train_cv)]\n",
    "\n",
    "# keep only columns with corr > 0.05\n",
    "if r_min:\n",
    "    col_keep = []\n",
    "    for c in X_train_t.columns:\n",
    "        min_v =X_train_t[c].values.min()\n",
    "        max_v = X_train_t[c].values.max()\n",
    "\n",
    "        if min_v < max_v:\n",
    "            r = scipy.stats.pearsonr(X_train_t[c].values, y_train_t)[0]\n",
    "            if ~np.isnan(r) and r > r_min:\n",
    "                col_keep.append(c)\n",
    "    \n",
    "    if len(col_keep) == 0:\n",
    "        print('No values returned')\n",
    "\n",
    "    X_train_t = X_train_t[col_keep]\n",
    "else:\n",
    "    col_keep =  X_train_t.columns.values.tolist()\n",
    "\n",
    "\n",
    "X_test_t = X[X.index.isin(test_cv)]\n",
    "y_test_t = y[y.index.isin(test_cv)]\n",
    "\n",
    "if r_min:\n",
    "    X_test_t = X_test_t[col_keep]\n",
    "\n",
    "clf.fit(X_train_t, y_train_t)\n",
    "\n",
    "y_pred = clf.predict(X_test_t)\n",
    "\n",
    "coefficients = clf.coef_[0]\n",
    "imp_random = {col_keep[i]: coefficients[i] for i in range(len(col_keep))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1860e513-bb71-442c-953a-430a010f5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp_r = pd.DataFrame(imp_random, index=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "127234b5-3f34-4ef3-bbf2-5418a4219a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prawo                       2.253462\n",
       "państwo                     1.274832\n",
       "mieć                        1.266063\n",
       "sprawa                      1.017545\n",
       "człowiek                    1.197414\n",
       "                              ...   \n",
       "krajowy rada                0.257708\n",
       "mieć miejsce                0.344423\n",
       "większość parlamentarny     0.340647\n",
       "trybunał sprawiedliwość     0.344886\n",
       "krajowy rada sądownictwo    0.301874\n",
       "Length: 171, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61061665-231c-4827-bde1-b94f39b2419f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
