{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beffabc2",
   "metadata": {},
   "source": [
    "- https://github.com/ksopyla/awesome-nlp-polish\n",
    "- Sentiment: https://pypi.org/project/sentimentpl/\n",
    "- Auto correct: https://github.com/filyp/autocorrect\n",
    "- other: https://github.com/sdadas/polish-nlp-resources\n",
    "- papers: https://homados.ipipan.waw.pl/?page_id=93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1652209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sentimentpl.models import SentimentPLModel\n",
    "from autocorrect import Speller\n",
    "from transformers import HerbertTokenizer, RobertaModel\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b985b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4228f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer#for word embedding\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ff0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_core = spacy.load(\"pl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216caffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentPLModel(from_pretrained='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406c7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller('pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe28bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_herbert = HerbertTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "# model_roberta = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df966dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_pl = spacy.load('pl_spacy_model') # or spacy.load('pl_spacy_model_morfeusz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45767664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_przyp(txt):\n",
    "    if txt != txt:\n",
    "        return np.nan\n",
    "    \n",
    "    txt_out = txt\n",
    "    \n",
    "    if \"przyp. Demagog\" in txt:\n",
    "        txt_out = (txt_out\n",
    "                   .replace('(','').replace(')','')\n",
    "                   .replace(' – przyp. Demagog','')\n",
    "                   .replace('- red.', ''))\n",
    "    if \"(…)\" in txt:\n",
    "        txt_out =  txt_out.replace('(…)','')\n",
    "    if \"(...)\" in txt:\n",
    "        txt_out =  txt_out.replace('(...)','')\n",
    "    if \"[\" in txt:\n",
    "        txt_out = txt_out.replace('[','').replace(']','')\n",
    "        \n",
    "    txt_out = re.sub(\"@[A-Za-z0-9]+\",\"\",txt_out) #Remove @ sign\n",
    "    txt_out = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", txt_out) #Remove http links\n",
    "    \n",
    "    txt_out = unicodedata.normalize(\"NFKD\", txt_out) #cleaning html\n",
    "    \n",
    "    txt_out = txt_out.replace(';', '.').replace('  ', ' ')\n",
    "    \n",
    "    return txt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8db48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(txt):\n",
    "    \n",
    "    doc = nlp_core(txt)\n",
    "    \n",
    "    out_dict = {}\n",
    "    \n",
    "    lemmas_list = []\n",
    "    tokens_list = []\n",
    "    sentiments_list = []\n",
    "    embeddings_list = []\n",
    "\n",
    "    error_n = 0\n",
    "\n",
    "    adj_n = 0\n",
    "    adv_n = 0\n",
    "    noun_n = 0\n",
    "    ent_n = 0\n",
    "\n",
    "    out_dict['sentiment_all'] = model(doc.text).item()\n",
    "    \n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        s = model(sent.text).item()\n",
    "        sentiments_list.append(s)\n",
    "    \n",
    "    out_dict['sentiment_avg'] = np.mean(sentiments_list)\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SPACE', 'PUNCT']:\n",
    "            lemmas_list.append(token.lemma_)\n",
    "            tokens_list.append(token.text)\n",
    "            corrected = spell(token.text)\n",
    "            if corrected != token.text:\n",
    "                error_n += 1\n",
    "\n",
    "        if token.pos_ == 'ADJ': \n",
    "            adj_n += 1\n",
    "        elif token.pos_ == 'ADV':\n",
    "            adv_n += 1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun_n += 1\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        ent_n += 1\n",
    "\n",
    "    tokens_list = list(set(tokens_list))\n",
    "    lemmas_list = list(set(lemmas_list))\n",
    "\n",
    "    out_dict['uniq_words'] = len(tokens_list)\n",
    "    out_dict['sentiment_lemm'] =  len(lemmas_list)\n",
    "    out_dict['err'] =  error_n\n",
    "    out_dict['net'] = ent_n\n",
    "    out_dict['ADJ'] = adj_n/len(tokens_list)\n",
    "    out_dict['ADV'] = adv_n/len(tokens_list)\n",
    "    out_dict['NOUN'] = noun_n/len(tokens_list)\n",
    "    \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32386f33",
   "metadata": {},
   "source": [
    "# Demagog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b242da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4924, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/scrapped/demagog.csv', sep=';')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d88d460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4922, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[df['text'].str.len() > 0 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9b541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].apply(lambda x: clean_przyp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad02a750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4917, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['text_clean'].str.len() > 1 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb273b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4917/4917 [19:07<00:00,  4.28it/s]\n"
     ]
    }
   ],
   "source": [
    "df['raw_dict'] = df['text_clean'].progress_apply(lambda x: extract_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e130e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.join( df['raw_dict'].apply(pd.Series).rename(columns={'sentiment_lemm' : 'uniq_lemm'}) ).drop('raw_dict', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf9dde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../datasets/scrapped/demagog_features.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4551537",
   "metadata": {},
   "source": [
    "# OKO.press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d811236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2869,)\n",
      "(2869, 9)\n"
     ]
    }
   ],
   "source": [
    "df_oko_raw = pd.read_csv('../datasets/oko.press/query_result.tsv', sep='\\t')\n",
    "\n",
    "print(df_oko_raw['Id wypowiedzi'].unique().shape)\n",
    "\n",
    "df_oko = pd.merge(\n",
    "    df_oko_raw.pivot(index=['Id wypowiedzi'], columns='Nazwa pola danych', values='Wartość pola danych').reset_index(),\n",
    "    df_oko_raw[~df_oko_raw['Autor Wypowiedzi'].isin(['Link do hasła', 'Nazwa słupka', 'Wesprzyj nas'])] \\\n",
    "        [['Id wypowiedzi', 'Autor Wypowiedzi']].dropna(),\n",
    "    on='Id wypowiedzi',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(df_oko.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c61491d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id wypowiedzi</th>\n",
       "      <th>sub_date</th>\n",
       "      <th>sub_hiperlacze</th>\n",
       "      <th>sub_napis</th>\n",
       "      <th>sub_napis_autor_wypowiedzi</th>\n",
       "      <th>sub_podpis</th>\n",
       "      <th>sub_stan_zegara</th>\n",
       "      <th>sub_title_text_after</th>\n",
       "      <th>Autor Wypowiedzi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1069</td>\n",
       "      <td>20160511</td>\n",
       "      <td>http://www.polskieradio.pl/7/129/Artykul/16180...</td>\n",
       "      <td>Rządy Tuska to również doprowadzenie do wyzysk...</td>\n",
       "      <td>1067</td>\n",
       "      <td>„Sygnały Dnia”, Polskie Radio</td>\n",
       "      <td>falsz</td>\n",
       "      <td>Fałsz - wycieka kilka razy mniej</td>\n",
       "      <td>Stanisław Piotrowicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1172</td>\n",
       "      <td>20160511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absurdy i marnotrawstwo pokazuje najlepiej pro...</td>\n",
       "      <td>1026</td>\n",
       "      <td>Sejm</td>\n",
       "      <td>blisko_prawdy</td>\n",
       "      <td>Jest moździerz, nie ma amunicji</td>\n",
       "      <td>Antoni Macierewicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1180</td>\n",
       "      <td>20160511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Przez 15 lat finansowaliście budowę korwety Ga...</td>\n",
       "      <td>1026</td>\n",
       "      <td>Sejm</td>\n",
       "      <td>blisko_prawdy</td>\n",
       "      <td>Niedokończony okręt za miliard złotych</td>\n",
       "      <td>Antoni Macierewicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>20160516</td>\n",
       "      <td>http://www.tokfm.pl/Tokfm/1,145400,20083911,mo...</td>\n",
       "      <td>Dzisiaj ponad 65 procent długu państwowego jes...</td>\n",
       "      <td>1257</td>\n",
       "      <td>TOK FM</td>\n",
       "      <td>falsz</td>\n",
       "      <td>Fałsz - pomylił się o 92 miliardy</td>\n",
       "      <td>Mateusz Morawiecki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1411</td>\n",
       "      <td>20160512</td>\n",
       "      <td>https://www.wprost.pl/kraj/10006923/Polska-jes...</td>\n",
       "      <td>Polska jest gotowa przyjąć każdego uchodźcę, k...</td>\n",
       "      <td>1076</td>\n",
       "      <td>Wywiad dla tygodnika „Mclean’s” za: Prezydent.pl</td>\n",
       "      <td>falsz</td>\n",
       "      <td>Fałsz - Duda bez pokrycia</td>\n",
       "      <td>Andrzej Duda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id wypowiedzi  sub_date                                     sub_hiperlacze  \\\n",
       "0           1069  20160511  http://www.polskieradio.pl/7/129/Artykul/16180...   \n",
       "1           1172  20160511                                                NaN   \n",
       "2           1180  20160511                                                NaN   \n",
       "3           1261  20160516  http://www.tokfm.pl/Tokfm/1,145400,20083911,mo...   \n",
       "4           1411  20160512  https://www.wprost.pl/kraj/10006923/Polska-jes...   \n",
       "\n",
       "                                           sub_napis  \\\n",
       "0  Rządy Tuska to również doprowadzenie do wyzysk...   \n",
       "1  Absurdy i marnotrawstwo pokazuje najlepiej pro...   \n",
       "2  Przez 15 lat finansowaliście budowę korwety Ga...   \n",
       "3  Dzisiaj ponad 65 procent długu państwowego jes...   \n",
       "4  Polska jest gotowa przyjąć każdego uchodźcę, k...   \n",
       "\n",
       "  sub_napis_autor_wypowiedzi  \\\n",
       "0                       1067   \n",
       "1                       1026   \n",
       "2                       1026   \n",
       "3                       1257   \n",
       "4                       1076   \n",
       "\n",
       "                                         sub_podpis sub_stan_zegara  \\\n",
       "0                     „Sygnały Dnia”, Polskie Radio           falsz   \n",
       "1                                              Sejm   blisko_prawdy   \n",
       "2                                              Sejm   blisko_prawdy   \n",
       "3                                            TOK FM           falsz   \n",
       "4  Wywiad dla tygodnika „Mclean’s” za: Prezydent.pl           falsz   \n",
       "\n",
       "                     sub_title_text_after      Autor Wypowiedzi  \n",
       "0        Fałsz - wycieka kilka razy mniej  Stanisław Piotrowicz  \n",
       "1         Jest moździerz, nie ma amunicji    Antoni Macierewicz  \n",
       "2  Niedokończony okręt za miliard złotych    Antoni Macierewicz  \n",
       "3       Fałsz - pomylił się o 92 miliardy    Mateusz Morawiecki  \n",
       "4               Fałsz - Duda bez pokrycia          Andrzej Duda  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oko.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24a239a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oko_fin = df_oko[['sub_napis', 'sub_stan_zegara', 'Autor Wypowiedzi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9d2b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2869/2869 [00:00<00:00, 191701.05it/s]\n",
      "/tmp/ipykernel_4534/3568069148.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_oko_fin['text_clean'] = df_oko_fin['sub_napis'].progress_apply(lambda x: clean_przyp(x))\n"
     ]
    }
   ],
   "source": [
    "df_oko_fin['text_clean'] = df_oko_fin['sub_napis'].progress_apply(lambda x: clean_przyp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7177d9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2869/2869 [10:48<00:00,  4.43it/s]\n",
      "/tmp/ipykernel_4534/2899795223.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_oko_fin['raw_dict'] = df_oko_fin['text_clean'].progress_apply(lambda x: extract_features(x))\n"
     ]
    }
   ],
   "source": [
    "df_oko_fin['raw_dict'] = df_oko_fin['text_clean'].progress_apply(lambda x: extract_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3679a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oko_clean = df_oko_fin.join( df_oko_fin['raw_dict'].apply(pd.Series).rename(columns={'sentiment_lemm' : 'uniq_lemm'}) ).drop('raw_dict', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2318365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oko_clean.to_csv('../datasets/oko.press/okopress_features.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91030594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
