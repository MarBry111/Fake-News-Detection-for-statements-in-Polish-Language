{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T15:08:17.772784Z",
     "iopub.status.busy": "2022-11-27T15:08:17.772405Z",
     "iopub.status.idle": "2022-11-27T15:08:43.369468Z",
     "shell.execute_reply": "2022-11-27T15:08:43.368328Z",
     "shell.execute_reply.started": "2022-11-27T15:08:17.772745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stylo_metrix.pipeline.stylo_metrix_pipe.StyloMetrixPipe at 0x7f846d33cbe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import time\n",
    "# import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from tqdm.notebook import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.base import clone as sklearn_clone\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
    ")\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from transformers import AutoTokenizer, AutoModel, HerbertTokenizer, BatchEncoding\n",
    "\n",
    "# import gc\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# import scipy\n",
    "# from scipy import spatial\n",
    "\n",
    "# import umap.umap_ as umap\n",
    "\n",
    "import spacy\n",
    "import stylo_metrix\n",
    "\n",
    "nlp = spacy.load('pl_nask_large')         # for Polish\n",
    "nlp.add_pipe(\"stylo_metrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T15:08:43.373442Z",
     "iopub.status.busy": "2022-11-27T15:08:43.372540Z",
     "iopub.status.idle": "2022-11-27T15:08:43.390384Z",
     "shell.execute_reply": "2022-11-27T15:08:43.388887Z",
     "shell.execute_reply.started": "2022-11-27T15:08:43.373390Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(111)\n",
    "random.seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T15:08:43.393489Z",
     "iopub.status.busy": "2022-11-27T15:08:43.392592Z",
     "iopub.status.idle": "2022-11-27T15:08:43.451933Z",
     "shell.execute_reply": "2022-11-27T15:08:43.450432Z",
     "shell.execute_reply.started": "2022-11-27T15:08:43.393432Z"
    }
   },
   "outputs": [],
   "source": [
    "df_topics = pd.read_csv('../datasets/ready2use/topics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T15:08:43.456831Z",
     "iopub.status.busy": "2022-11-27T15:08:43.456352Z",
     "iopub.status.idle": "2022-11-27T15:08:43.636702Z",
     "shell.execute_reply": "2022-11-27T15:08:43.635861Z",
     "shell.execute_reply.started": "2022-11-27T15:08:43.456788Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/ready2use/fake_news_features_combined.csv', sep=';')\n",
    "\n",
    "df = df[ df['assestment'] != 'brak' ]\n",
    "\n",
    "df.loc[:, 'assestment'] = df['assestment'].replace({\n",
    "    'falsz' : 'Fałsz',\n",
    "    'zbity_zegar' : 'Fałsz',\n",
    "    'raczej_falsz' : 'Fałsz',\n",
    "    'prawda' : 'Prawda',\n",
    "    'blisko_prawdy' : 'Prawda',\n",
    "    'polprawda' : 'Manipulacja',\n",
    "    'Częściowy fałsz' : 'Manipulacja'\n",
    "})\n",
    "\n",
    "df = df[ df['assestment'] != 'Nieweryfikowalne' ]\n",
    "df = df[ df['assestment'] != 'Manipulacja' ]\n",
    "\n",
    "df['assestment'] = df['assestment'].replace({\n",
    "    'Fałsz' : 0,\n",
    "#     'Manipulacja' : 1,\n",
    "    'Prawda' : 1\n",
    "}).astype(int)\n",
    "\n",
    "df = df.copy()[['assestment', 'text_clean']][df.index.isin(df_topics.index)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T15:08:47.594715Z",
     "iopub.status.busy": "2022-11-27T15:08:47.594342Z",
     "iopub.status.idle": "2022-11-27T15:08:47.632847Z",
     "shell.execute_reply": "2022-11-27T15:08:47.631805Z",
     "shell.execute_reply.started": "2022-11-27T15:08:47.594681Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_fold = []\n",
    "cv_fold_i = []\n",
    "\n",
    "for i in df_topics['topic'].unique().reshape(10,-1):\n",
    "    train_cv = df_topics.index[ ~np.isin(df_topics[\"topic\"], [i, np.mod(i+1,10)]) ].values\n",
    "    val_cv = df_topics.index[ ~np.isin(df_topics[\"topic\"], np.mod(i+1,10)) ].values\n",
    "    test_cv = df_topics.index[ np.isin(df_topics[\"topic\"], i) ].values\n",
    "    \n",
    "    train_cv_i = df_topics.reset_index().index[ ~np.isin(df_topics[\"topic\"], [i, np.mod(i+1,10)]) ].values\n",
    "    val_cv_i = df_topics.reset_index().index[ ~np.isin(df_topics[\"topic\"], np.mod(i+1,10)) ].values\n",
    "    test_cv_i = df_topics.reset_index().index[ np.isin(df_topics[\"topic\"], i) ].values\n",
    "    \n",
    "    cv_fold.append( [train_cv, val_cv, test_cv])\n",
    "    cv_fold_i.append( [train_cv_i, val_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T15:08:47.635075Z",
     "iopub.status.busy": "2022-11-27T15:08:47.634315Z",
     "iopub.status.idle": "2022-11-27T15:08:47.687480Z",
     "shell.execute_reply": "2022-11-27T15:08:47.686035Z",
     "shell.execute_reply.started": "2022-11-27T15:08:47.635025Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "kf.get_n_splits(df_topics)\n",
    "\n",
    "cv_Kfold = []\n",
    "cv_Kfold_i = []\n",
    "\n",
    "for train_index, test_index in kf.split(df_topics):\n",
    "    train_index, val_index = train_test_split(train_index, test_size=1/9, shuffle=True)\n",
    "    train_cv = df_topics.iloc[ train_index, : ].index.values\n",
    "    val_cv = df_topics.iloc[ val_index, : ].index.values\n",
    "    test_cv = df_topics.iloc[ test_index, : ].index.values\n",
    "\n",
    "    train_cv_i= df_topics.reset_index().iloc[ train_index, : ].index.values\n",
    "    val_cv_i = df_topics.reset_index().iloc[ val_index, : ].index.values\n",
    "    test_cv_i = df_topics.reset_index().iloc[ test_index, : ].index.values\n",
    "    \n",
    "    cv_Kfold.append( [train_cv, val_cv, test_cv])\n",
    "    cv_Kfold_i.append( [train_cv_i, val_cv_i, test_cv_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = df['text_clean'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec_stylo(txt):\n",
    "    doc = nlp(txt)\n",
    "    vec = []\n",
    "    for metric in doc._.smv:\n",
    "        vec.append(metric['value'])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6541/6541 [29:08<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_style = [get_vec_stylo(t) for t in tqdm(df['text_clean'].values, position=0, leave=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6541, 89)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(emb_style).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/ready2use/style_emb_pl.npy', 'wb') as f:\n",
    "    np.save(f, np.array(emb_style) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T15:53:33.387287Z",
     "iopub.status.busy": "2022-11-26T15:53:33.386511Z",
     "iopub.status.idle": "2022-11-26T15:53:33.402885Z",
     "shell.execute_reply": "2022-11-26T15:53:33.401582Z",
     "shell.execute_reply.started": "2022-11-26T15:53:33.387245Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, val_index, test_index = cv_fold_i[np.random.randint(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T15:53:34.027251Z",
     "iopub.status.busy": "2022-11-26T15:53:34.026899Z",
     "iopub.status.idle": "2022-11-26T15:53:34.163303Z",
     "shell.execute_reply": "2022-11-26T15:53:34.161895Z",
     "shell.execute_reply.started": "2022-11-26T15:53:34.027223Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_accuracy' : [],\n",
    "    'test_precision' : [],\n",
    "    'test_recall' : [],\n",
    "    'test_f1' : []\n",
    "}\n",
    "\n",
    "\n",
    "y_train_t = df['assestment'].values[train_index]\n",
    "X_train_t = np.array(emb_style)[train_index,:]\n",
    "y_test_t = df['assestment'].values[train_index]\n",
    "X_test_t = np.array(emb_style)[train_index,:]\n",
    "\n",
    "clf_lr_1.fit(X_train_t, y_train_t)\n",
    "\n",
    "y_pred = clf_lr_1.predict(X_test_t)\n",
    "\n",
    "results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": np.array(results['test_accuracy']),\n",
    "#     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "#     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "    \"F1 Score\":  np.array(results['test_f1']),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T15:53:34.788113Z",
     "iopub.status.busy": "2022-11-26T15:53:34.787753Z",
     "iopub.status.idle": "2022-11-26T15:53:34.799721Z",
     "shell.execute_reply": "2022-11-26T15:53:34.798092Z",
     "shell.execute_reply.started": "2022-11-26T15:53:34.788083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1825,  909],\n",
       "       [ 952, 1595]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_t, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T15:53:36.407665Z",
     "iopub.status.busy": "2022-11-26T15:53:36.406494Z",
     "iopub.status.idle": "2022-11-26T15:53:36.415616Z",
     "shell.execute_reply": "2022-11-26T15:53:36.414441Z",
     "shell.execute_reply.started": "2022-11-26T15:53:36.407618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': array([0.64760462]), 'F1 Score': array([0.63155811])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T18:28:29.816271Z",
     "iopub.status.busy": "2022-11-25T18:28:29.815893Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_accuracy' : [],\n",
    "    'test_precision' : [],\n",
    "    'test_recall' : [],\n",
    "    'test_f1' : []\n",
    "}\n",
    "\n",
    "embedding_dims = 100\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "lr = 0.001\n",
    "\n",
    "for j, (train_index, val_index, test_index) in enumerate(cv_fold_i):\n",
    "    train_ds = FakeNews(embeddings_table, df['assestment'].values, train_index)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    val_ds = FakeNews(embeddings_table, df['assestment'].values, val_index)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_ds = FakeNews(embeddings_table, df['assestment'].values, test_index)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size//2, shuffle=False, num_workers=2)\n",
    "\n",
    "    \n",
    "    model = Network(embedding_dims)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = TripletLoss()\n",
    "\n",
    "    val_prev = np.inf\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=f\"Epochs {j}\"):\n",
    "        running_loss = []\n",
    "        for step, (anchor_claim, positive_claim, negative_claim, anchor_label) in enumerate(train_loader):\n",
    "            anchor_claim = anchor_claim.to(device)\n",
    "            positive_claim = positive_claim.to(device)\n",
    "            negative_claim = negative_claim.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = model(anchor_claim)\n",
    "            positive_out = model(positive_claim)\n",
    "            negative_out = model(negative_claim)\n",
    "\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = []\n",
    "        for anchor_claim, positive_claim, negative_claim, _ in val_loader:\n",
    "            anchor_claim = anchor_claim.to(device)\n",
    "            positive_claim = positive_claim.to(device)\n",
    "            negative_claim = negative_claim.to(device)\n",
    "\n",
    "            anchor_out = model(anchor_claim)\n",
    "            positive_out = model(positive_claim)\n",
    "            negative_out = model(negative_claim)\n",
    "\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            val_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        if np.mean(val_loss) < val_prev:\n",
    "            val_prev = np.mean(val_loss)\n",
    "            torch.save(model, f'model_cv{j}.pt')\n",
    "        \n",
    "        if epoch%100 == 0:\n",
    "            print(f\"{j} Epoch: {epoch+1}/{epochs} - Train Loss: {np.mean(running_loss):.4f};\",\n",
    "                  f\" Val Loss: {np.mean(val_loss):.4f} Val loss best {val_prev:.4f}\"\n",
    "             )\n",
    "            \n",
    "    \n",
    "    train_results = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for claim, _, _, label in train_loader:\n",
    "            anchor_claim = claim.to(device)\n",
    "\n",
    "            train_results.append(model(anchor_claim).cpu().numpy())\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "    train_results = np.concatenate(train_results) \n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    \n",
    "    test_results = []\n",
    "    test_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for claim, _, _, label in test_loader:\n",
    "            anchor_claim = claim.to(device)\n",
    "\n",
    "            test_results.append(model(anchor_claim).cpu().numpy())\n",
    "            test_labels.append(label)\n",
    "\n",
    "\n",
    "    test_results = np.concatenate(test_results)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "\n",
    "    \n",
    "    clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "\n",
    "    y_train_t = labels\n",
    "    X_train_t = train_results\n",
    "    y_test_t = test_labels\n",
    "    X_test_t = test_results\n",
    "\n",
    "    clf_lr_1.fit(X_train_t, y_train_t)\n",
    "\n",
    "    y_pred = clf_lr_1.predict(X_test_t)\n",
    "\n",
    "    results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "    results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "    results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "    results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "\n",
    "out = {\n",
    "    \"Accuracy\": np.array(results['test_accuracy']),\n",
    "#     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "#     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "    \"F1 Score\":  np.array(results['test_f1']),\n",
    "    }\n",
    "\n",
    "print(\n",
    "    'triplet loss lr C1',\n",
    "    f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "    f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "    f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get use best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_accuracy' : [],\n",
    "    'test_precision' : [],\n",
    "    'test_recall' : [],\n",
    "    'test_f1' : []\n",
    "}\n",
    "\n",
    "\n",
    "for j, (train_index, val_index, test_index) in enumerate(cv_fold_i):\n",
    "    train_ds = FakeNews(embeddings_table, df['assestment'].values, train_index)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    val_ds = FakeNews(embeddings_table, df['assestment'].values, val_index)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_ds = FakeNews(embeddings_table, df['assestment'].values, test_index)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size//2, shuffle=False, num_workers=2)\n",
    "\n",
    "    \n",
    "    model = Network(embedding_dims)\n",
    "    model = torch.load(f'model_cv{j}.pt')\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "   \n",
    "    train_results = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for claim, _, _, label in train_loader:\n",
    "            anchor_claim = claim.to(device)\n",
    "\n",
    "            train_results.append(model(anchor_claim).cpu().numpy())\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "    train_results = np.concatenate(train_results) \n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    \n",
    "    test_results = []\n",
    "    test_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for claim, _, _, label in test_loader:\n",
    "            anchor_claim = claim.to(device)\n",
    "\n",
    "            test_results.append(model(anchor_claim).cpu().numpy())\n",
    "            test_labels.append(label)\n",
    "\n",
    "\n",
    "    test_results = np.concatenate(test_results)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "\n",
    "    \n",
    "    clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "\n",
    "    y_train_t = labels\n",
    "    X_train_t = train_results\n",
    "    y_test_t = test_labels\n",
    "    X_test_t = test_results\n",
    "\n",
    "    clf_lr_1.fit(X_train_t, y_train_t)\n",
    "\n",
    "    y_pred = clf_lr_1.predict(X_test_t)\n",
    "\n",
    "    results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "    results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "    results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "    results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "\n",
    "out = {\n",
    "    \"Accuracy\": np.array(results['test_accuracy']),\n",
    "#     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "#     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "    \"F1 Score\":  np.array(results['test_f1']),\n",
    "    }\n",
    "\n",
    "print(\n",
    "    'triplet loss lr C1',\n",
    "    f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "    f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "    f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_accuracy' : [],\n",
    "    'test_precision' : [],\n",
    "    'test_recall' : [],\n",
    "    'test_f1' : []\n",
    "}\n",
    "\n",
    "embedding_dims = 100\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "lr = 0.001\n",
    "\n",
    "for j, (train_index, val_index, test_index) in enumerate(cv_Kfold_i):\n",
    "    train_ds = FakeNews(embeddings_table, df['assestment'].values, train_index)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    val_ds = FakeNews(embeddings_table, df['assestment'].values, val_index)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_ds = FakeNews(embeddings_table, df['assestment'].values, test_index)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size//2, shuffle=False, num_workers=2)\n",
    "\n",
    "    \n",
    "    model = Network(embedding_dims)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = TripletLoss()\n",
    "\n",
    "    val_prev = np.inf\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=f\"Epochs {j}\"):\n",
    "        running_loss = []\n",
    "        for step, (anchor_claim, positive_claim, negative_claim, anchor_label) in enumerate(train_loader):\n",
    "            anchor_claim = anchor_claim.to(device)\n",
    "            positive_claim = positive_claim.to(device)\n",
    "            negative_claim = negative_claim.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = model(anchor_claim)\n",
    "            positive_out = model(positive_claim)\n",
    "            negative_out = model(negative_claim)\n",
    "\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = []\n",
    "        for anchor_claim, positive_claim, negative_claim, _ in val_loader:\n",
    "            anchor_claim = anchor_claim.to(device)\n",
    "            positive_claim = positive_claim.to(device)\n",
    "            negative_claim = negative_claim.to(device)\n",
    "\n",
    "            anchor_out = model(anchor_claim)\n",
    "            positive_out = model(positive_claim)\n",
    "            negative_out = model(negative_claim)\n",
    "\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            val_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        if np.mean(val_loss) < val_prev:\n",
    "            val_prev = np.mean(val_loss)\n",
    "            torch.save(model, f'model_cv{j}.pt')\n",
    "        \n",
    "        if epoch%100 == 0:\n",
    "            print(f\"{j} Epoch: {epoch+1}/{epochs} - Train Loss: {np.mean(running_loss):.4f};\",\n",
    "                  f\" Val Loss: {np.mean(val_loss):.4f} Val loss best {val_prev:.4f}\"\n",
    "             )\n",
    "            \n",
    "    \n",
    "    train_results = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for claim, _, _, label in train_loader:\n",
    "            anchor_claim = claim.to(device)\n",
    "\n",
    "            train_results.append(model(anchor_claim).cpu().numpy())\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "    train_results = np.concatenate(train_results) \n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    \n",
    "    test_results = []\n",
    "    test_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for claim, _, _, label in test_loader:\n",
    "            anchor_claim = claim.to(device)\n",
    "\n",
    "            test_results.append(model(anchor_claim).cpu().numpy())\n",
    "            test_labels.append(label)\n",
    "\n",
    "\n",
    "    test_results = np.concatenate(test_results)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "\n",
    "    \n",
    "    clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear')\n",
    "\n",
    "    y_train_t = labels\n",
    "    X_train_t = train_results\n",
    "    y_test_t = test_labels\n",
    "    X_test_t = test_results\n",
    "\n",
    "    clf_lr_1.fit(X_train_t, y_train_t)\n",
    "\n",
    "    y_pred = clf_lr_1.predict(X_test_t)\n",
    "\n",
    "    results['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \n",
    "    results['test_precision'].append( precision_score(y_test_t, y_pred) ) \n",
    "    results['test_recall'].append( recall_score(y_test_t, y_pred) ) \n",
    "    results['test_f1'].append( f1_score(y_test_t, y_pred) ) \n",
    "\n",
    "\n",
    "out = {\n",
    "    \"Accuracy\": np.array(results['test_accuracy']),\n",
    "#     \"Precision\": np.array(results['test_precision']).mean(),\n",
    "#     \"Recall\": np.array(results['test_recall']).mean(),\n",
    "    \"F1 Score\":  np.array(results['test_f1']),\n",
    "    }\n",
    "\n",
    "print(\n",
    "    'triplet loss lr C1',\n",
    "    f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n",
    "    f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n",
    "    f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
