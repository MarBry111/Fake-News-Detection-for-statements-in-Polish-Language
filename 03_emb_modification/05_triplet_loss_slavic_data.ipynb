{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory      \n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-19T17:27:36.221114Z","iopub.execute_input":"2022-11-19T17:27:36.221572Z","iopub.status.idle":"2022-11-19T17:27:36.239040Z","shell.execute_reply.started":"2022-11-19T17:27:36.221533Z","shell.execute_reply":"2022-11-19T17:27:36.238203Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/cz-dataset-fn/fake_news_features_cz_CZ.csv\n/kaggle/input/cz-dataset-fn/fake_news_features_cz_SK.csv\n/kaggle/input/fakenews-poland-clean-topics/embeddings_pl_herbert.csv\n/kaggle/input/fakenews-poland-clean-topics/topics.csv\n/kaggle/input/fakenews-poland-clean-topics/fake_news_features_combined.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentence-transformers\n!pip install transformers\n!pip install sacremoses","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:27:36.497792Z","iopub.execute_input":"2022-11-19T17:27:36.498106Z","iopub.status.idle":"2022-11-19T17:28:17.811075Z","shell.execute_reply.started":"2022-11-19T17:27:36.498073Z","shell.execute_reply":"2022-11-19T17:28:17.809948Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m968.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.20.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.7)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=d3e53224a47f28d24c68fd2df750958f15075066321ece4f75bbebf7dd23b2a1\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (0.0.53)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacremoses) (2021.11.10)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses) (8.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses) (1.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sacremoses) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses) (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.base import clone as sklearn_clone\n\nfrom sklearn.metrics import (\n    accuracy_score, \n    f1_score, \n    recall_score,\n    precision_score,\n    roc_auc_score, confusion_matrix, roc_curve, classification_report\n)\n\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModel, HerbertTokenizer, BatchEncoding\n\nimport gc\nfrom sklearn.manifold import TSNE","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:44:38.919494Z","iopub.execute_input":"2022-11-19T17:44:38.920398Z","iopub.status.idle":"2022-11-19T17:44:38.927463Z","shell.execute_reply.started":"2022-11-19T17:44:38.920358Z","shell.execute_reply":"2022-11-19T17:44:38.926351Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(111)\nnp.random.seed(111)\nrandom.seed(111)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif device.type == \"cuda\":\n    torch.cuda.get_device_name()\n    \ndevice.type","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:28:19.704840Z","iopub.execute_input":"2022-11-19T17:28:19.705690Z","iopub.status.idle":"2022-11-19T17:28:19.780938Z","shell.execute_reply.started":"2022-11-19T17:28:19.705647Z","shell.execute_reply":"2022-11-19T17:28:19.779952Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Get HerBERT","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/bert-base-bg-cs-pl-ru-cased\")\nmodel_slavic = AutoModel.from_pretrained(\"DeepPavlov/bert-base-bg-cs-pl-ru-cased\")","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:28:19.783179Z","iopub.execute_input":"2022-11-19T17:28:19.783600Z","iopub.status.idle":"2022-11-19T17:29:02.133730Z","shell.execute_reply.started":"2022-11-19T17:28:19.783565Z","shell.execute_reply":"2022-11-19T17:29:02.132736Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcb61274d8f845529189a23921357db7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6051c5812bca498f8e6b76df08019d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654143e569214119a862bfee3c36b51e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fa30505290440a8916c43e6f6320b22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5bc4aeb580442ba93cdcbc8d491d99"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/bert-base-bg-cs-pl-ru-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Get data","metadata":{}},{"cell_type":"code","source":"df_cz_cz = pd.read_csv('../input/cz-dataset-fn/fake_news_features_cz_CZ.csv', sep=';')\ndf_cz_sk = pd.read_csv('../input/cz-dataset-fn/fake_news_features_cz_SK.csv', sep=';')\n\ndf_cz = pd.concat([df_cz_sk, df_cz_sk])\n\n\ndf_cz['statementState'] = df_cz['statementState'].str.strip()\n\ndf_cz = df_cz[ df_cz['statementState'] != 'MISLEADING' ]\ndf_cz = df_cz[ df_cz['statementState'] != 'UNVERIFIABLE' ]\ndf_cz = df_cz[ df_cz['statementState'] != 'null' ]\n\ndf_cz = df_cz.reset_index(drop=True)\n\ndf_cz['assestment'] = df_cz['statementState'].replace({\n    'FALSE' : 0,\n#     'Manipulacja' : 1,\n    'TRUE' : 1\n}).astype(int)\n\ndf_cz = df_cz.copy()[['assestment', 'text_clean']].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:29:02.135712Z","iopub.execute_input":"2022-11-19T17:29:02.136486Z","iopub.status.idle":"2022-11-19T17:29:03.920923Z","shell.execute_reply.started":"2022-11-19T17:29:02.136445Z","shell.execute_reply":"2022-11-19T17:29:03.919922Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/fakenews-poland-clean-topics/fake_news_features_combined.csv', sep=';')\n\ndf = df[ df['assestment'] != 'brak' ]\n\ndf.loc[:, 'assestment'] = df['assestment'].replace({\n    'falsz' : 'Fałsz',\n    'zbity_zegar' : 'Fałsz',\n    'raczej_falsz' : 'Fałsz',\n    'prawda' : 'Prawda',\n    'blisko_prawdy' : 'Prawda',\n    'polprawda' : 'Manipulacja',\n    'Częściowy fałsz' : 'Manipulacja'\n})\n\ndf = df[ df['assestment'] != 'Nieweryfikowalne' ]\ndf = df[ df['assestment'] != 'Manipulacja' ]\n\ndf['assestment'] = df['assestment'].replace({\n    'Fałsz' : 0,\n#     'Manipulacja' : 1,\n    'Prawda' : 1\n}).astype(int)\n\ndf_pl = df.copy()[['assestment', 'text_clean']].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:34:56.901043Z","iopub.execute_input":"2022-11-19T17:34:56.901446Z","iopub.status.idle":"2022-11-19T17:34:56.976117Z","shell.execute_reply.started":"2022-11-19T17:34:56.901415Z","shell.execute_reply":"2022-11-19T17:34:56.975202Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":" model_slavic = model_slavic.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:29:40.345278Z","iopub.execute_input":"2022-11-19T17:29:40.345733Z","iopub.status.idle":"2022-11-19T17:29:40.595491Z","shell.execute_reply.started":"2022-11-19T17:29:40.345695Z","shell.execute_reply":"2022-11-19T17:29:40.594366Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"embeddings_table = np.zeros((df_cz.shape[0], 768))\n\nfor i, t in enumerate(tqdm(df_cz['text_clean'].values)):\n    encoded_input = tokenizer(t, return_tensors='pt', truncation=True, padding=True).to(device)\n    output = model_slavic(**encoded_input)[0][:,0]\n    embeddings_table[i,:] = output.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T17:29:42.856679Z","iopub.execute_input":"2022-11-19T17:29:42.857026Z","iopub.status.idle":"2022-11-19T17:32:51.865619Z","shell.execute_reply.started":"2022-11-19T17:29:42.856997Z","shell.execute_reply":"2022-11-19T17:32:51.864523Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19314 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6293a761ad9457ab235e8ceff04ac2e"}},"metadata":{}}]},{"cell_type":"code","source":"embeddings_table_pl = np.zeros((df_pl.shape[0], 768))\n\nfor i, t in enumerate(tqdm(df_pl['text_clean'].values)):\n    encoded_input = tokenizer(t, return_tensors='pt', truncation=True, padding=True).to(device)\n    output = model_slavic(**encoded_input)[0][:,0]\n    embeddings_table_pl[i,:] = output.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:03:52.543462Z","iopub.execute_input":"2022-11-19T18:03:52.543857Z","iopub.status.idle":"2022-11-19T18:04:57.371249Z","shell.execute_reply.started":"2022-11-19T18:03:52.543826Z","shell.execute_reply":"2022-11-19T18:04:57.370287Z"},"trusted":true},"execution_count":92,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a18a1fdd58664e81a3a037e9b40e55f5"}},"metadata":{}}]},{"cell_type":"code","source":"class FakeNews(Dataset):\n    def __init__(self, emb_dt, y_dt):\n        self.emb = emb_dt\n        \n        self.labels = y_dt\n        \n        self.index = np.arange(self.emb.shape[0])\n        \n    def __len__(self):\n        return len(self.emb)\n    \n    def __getitem__(self, item):\n        anchor_label = self.labels[item]\n\n        positive_list = self.index[self.index!=item][self.labels[self.index!=item]==anchor_label]\n\n        positive_item = random.choice(positive_list)\n        \n        negative_list = self.index[self.index!=item][self.labels[self.index!=item]!=anchor_label]\n        negative_item = random.choice(negative_list)\n        \n        anchor_claim = self.emb[item].astype(np.float32)\n        positive_claim = self.emb[positive_item].astype(np.float32)\n        negative_claim = self.emb[negative_item].astype(np.float32)\n\n        anchor_label = anchor_label.astype(np.float32)\n\n        return anchor_claim, positive_claim, negative_claim, anchor_label","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.373286Z","iopub.execute_input":"2022-11-19T18:04:57.373886Z","iopub.status.idle":"2022-11-19T18:04:57.383637Z","shell.execute_reply.started":"2022-11-19T18:04:57.373845Z","shell.execute_reply":"2022-11-19T18:04:57.382582Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"embedding_dims = 100\nbatch_size = 128\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.386770Z","iopub.execute_input":"2022-11-19T18:04:57.387071Z","iopub.status.idle":"2022-11-19T18:04:57.394754Z","shell.execute_reply.started":"2022-11-19T18:04:57.387043Z","shell.execute_reply":"2022-11-19T18:04:57.393786Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"## TripletLoss","metadata":{}},{"cell_type":"code","source":"class TripletLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n        \n    def calc_euclidean(self, x1, x2):\n        return (x1 - x2).pow(2).sum(1)\n    \n    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n        distance_positive = self.calc_euclidean(anchor, positive)\n        distance_negative = self.calc_euclidean(anchor, negative)\n        losses = torch.relu(distance_positive - distance_negative + self.margin)\n\n        return losses.mean()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.397579Z","iopub.execute_input":"2022-11-19T18:04:57.398054Z","iopub.status.idle":"2022-11-19T18:04:57.406388Z","shell.execute_reply.started":"2022-11-19T18:04:57.398014Z","shell.execute_reply":"2022-11-19T18:04:57.405095Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"## Define Net","metadata":{}},{"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self, emb_dim=128):\n        super(Network, self).__init__()\n        \n        self.fc = nn.Sequential(\n            nn.Linear(768, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            \n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            \n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            \n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, emb_dim)\n        )\n        \n    def forward(self, x):\n        x = x.view(-1, 768)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.408608Z","iopub.execute_input":"2022-11-19T18:04:57.408905Z","iopub.status.idle":"2022-11-19T18:04:57.418713Z","shell.execute_reply.started":"2022-11-19T18:04:57.408879Z","shell.execute_reply":"2022-11-19T18:04:57.417633Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"## Some testing one one kfold","metadata":{}},{"cell_type":"code","source":"train_ds = FakeNews(embeddings_table, df_cz['assestment'].values)\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n\ntest_ds = FakeNews(embeddings_table_pl, df_pl['assestment'].values)\ntest_loader = DataLoader(test_ds, batch_size=batch_size//2, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.420086Z","iopub.execute_input":"2022-11-19T18:04:57.420523Z","iopub.status.idle":"2022-11-19T18:04:57.433041Z","shell.execute_reply.started":"2022-11-19T18:04:57.420488Z","shell.execute_reply":"2022-11-19T18:04:57.432202Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"model = Network(embedding_dims)\n# model = torch.nn.DataParallel(model)\nmodel = torch.jit.script(model).to(device)\n# model = model.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.jit.script(TripletLoss())\n# criterion = TripletLoss()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.434342Z","iopub.execute_input":"2022-11-19T18:04:57.434708Z","iopub.status.idle":"2022-11-19T18:04:57.521589Z","shell.execute_reply.started":"2022-11-19T18:04:57.434670Z","shell.execute_reply":"2022-11-19T18:04:57.520747Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"model.train()\nfor epoch in tqdm(range(epochs), desc=\"Epochs\"):\n    running_loss = []\n    for step, (anchor_claim, positive_claim, negative_claim, anchor_label) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n        anchor_claim = anchor_claim.to(device)\n        positive_claim = positive_claim.to(device)\n        negative_claim = negative_claim.to(device)\n\n        optimizer.zero_grad()\n        anchor_out = model(anchor_claim)\n        positive_out = model(positive_claim)\n        negative_out = model(negative_claim)\n        \n        loss = criterion(anchor_out, positive_out, negative_out)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss.append(loss.cpu().detach().numpy())\n        \n    print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss)))","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:04:57.524044Z","iopub.execute_input":"2022-11-19T18:04:57.524638Z","iopub.status.idle":"2022-11-19T18:06:09.933663Z","shell.execute_reply.started":"2022-11-19T18:04:57.524602Z","shell.execute_reply":"2022-11-19T18:06:09.932480Z"},"trusted":true},"execution_count":99,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04eab08a8740423f85b190ba701483b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 1/10 - Loss: 1.5089\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 2/10 - Loss: 0.8967\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 3/10 - Loss: 0.6617\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 4/10 - Loss: 0.6286\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 5/10 - Loss: 0.4918\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 6/10 - Loss: 0.4172\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 7/10 - Loss: 0.3934\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 8/10 - Loss: 0.3603\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 9/10 - Loss: 0.3237\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch: 10/10 - Loss: 0.3479\n","output_type":"stream"}]},{"cell_type":"code","source":"train_results = []\nlabels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for claim, _, _, label in tqdm(train_loader):\n        anchor_claim = claim.to(device)\n        \n        train_results.append(model(anchor_claim).cpu().numpy())\n        labels.append(label)\n        \n#         del anchor_claim \n#         gc.collect()\n#         torch.cuda.empty_cache()\n\ntrain_results = np.concatenate(train_results) \nlabels = np.concatenate(labels)\ntrain_results.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:06:09.935933Z","iopub.execute_input":"2022-11-19T18:06:09.936748Z","iopub.status.idle":"2022-11-19T18:06:16.334698Z","shell.execute_reply.started":"2022-11-19T18:06:09.936705Z","shell.execute_reply":"2022-11-19T18:06:16.325957Z"},"trusted":true},"execution_count":100,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/151 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e82ec1890e7a41e89216b165bdf13cc3"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"(19314, 100)"},"metadata":{}}]},{"cell_type":"code","source":"test_results = []\ntest_labels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for claim, _, _, label in tqdm(test_loader):\n        anchor_claim = claim.to(device)\n        \n        test_results.append(model(anchor_claim).cpu().numpy())\n        test_labels.append(label)\n        \n#         del anchor_claim \n#         gc.collect()\n#         torch.cuda.empty_cache()\n\ntest_results = np.concatenate(test_results)\ntest_labels = np.concatenate(test_labels)\ntest_results.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:06:16.343596Z","iopub.execute_input":"2022-11-19T18:06:16.347627Z","iopub.status.idle":"2022-11-19T18:06:18.291195Z","shell.execute_reply.started":"2022-11-19T18:06:16.347558Z","shell.execute_reply":"2022-11-19T18:06:18.290007Z"},"trusted":true},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/103 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ce3e2b320b4c70aefab02363f47005"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"(6542, 100)"},"metadata":{}}]},{"cell_type":"code","source":"clf_lr_1 = LogisticRegression(max_iter=5000, C=1, penalty='l2', solver='liblinear', class_weight='balanced')","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:07:46.420976Z","iopub.execute_input":"2022-11-19T18:07:46.421355Z","iopub.status.idle":"2022-11-19T18:07:46.426831Z","shell.execute_reply.started":"2022-11-19T18:07:46.421323Z","shell.execute_reply":"2022-11-19T18:07:46.425560Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"results = {\n    'test_accuracy' : [],\n    'test_precision' : [],\n    'test_recall' : [],\n    'test_f1' : []\n}\n\n\ny_train_t = labels\nX_train_t = train_results\ny_test_t = test_labels\nX_test_t = test_results\n\nclf_lr_1.fit(X_train_t, y_train_t)\n\ny_pred = clf_lr_1.predict(X_test_t)\n\nresults['test_accuracy'].append( accuracy_score(y_test_t, y_pred) ) \nresults['test_precision'].append( precision_score(y_test_t, y_pred) ) \nresults['test_recall'].append( recall_score(y_test_t, y_pred) ) \nresults['test_f1'].append( f1_score(y_test_t, y_pred) ) \n\nout = {\n    \"Accuracy\": np.array(results['test_accuracy']).mean(),\n    \"Precision\": np.array(results['test_precision']).mean(),\n    \"Recall\": np.array(results['test_recall']).mean(),\n    \"F1 Score\":  np.array(results['test_f1']).mean(),\n    }","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:07:48.895026Z","iopub.execute_input":"2022-11-19T18:07:48.895535Z","iopub.status.idle":"2022-11-19T18:07:50.213904Z","shell.execute_reply.started":"2022-11-19T18:07:48.895495Z","shell.execute_reply":"2022-11-19T18:07:50.212497Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"print(\n    'triplet loss lr C1',\n    f'Accuracy {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f}',\n    f'F1 Score {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}',\n    f' {out[\"Accuracy\"].mean():.3f}+-{out[\"Accuracy\"].std():.3f} | {out[\"F1 Score\"].mean():.3f}+-{out[\"F1 Score\"].std():.3f}'\n)    ","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:07:50.243730Z","iopub.execute_input":"2022-11-19T18:07:50.244354Z","iopub.status.idle":"2022-11-19T18:07:50.253309Z","shell.execute_reply.started":"2022-11-19T18:07:50.244294Z","shell.execute_reply":"2022-11-19T18:07:50.252193Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"triplet loss lr C1 Accuracy 0.485+-0.000 F1 Score 0.523+-0.000  0.485+-0.000 | 0.523+-0.000\n","output_type":"stream"}]},{"cell_type":"code","source":"confusion_matrix(y_test_t, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:07:55.347237Z","iopub.execute_input":"2022-11-19T18:07:55.347771Z","iopub.status.idle":"2022-11-19T18:07:55.377818Z","shell.execute_reply.started":"2022-11-19T18:07:55.347736Z","shell.execute_reply":"2022-11-19T18:07:55.375627Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"array([[1333, 2106],\n       [1260, 1843]])"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_train = clf_lr_1.predict(X_train_t)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:07:56.380535Z","iopub.execute_input":"2022-11-19T18:07:56.380997Z","iopub.status.idle":"2022-11-19T18:07:56.394791Z","shell.execute_reply.started":"2022-11-19T18:07:56.380962Z","shell.execute_reply":"2022-11-19T18:07:56.393373Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_train_t, y_pred_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:07:57.061953Z","iopub.execute_input":"2022-11-19T18:07:57.062361Z","iopub.status.idle":"2022-11-19T18:07:57.087029Z","shell.execute_reply.started":"2022-11-19T18:07:57.062326Z","shell.execute_reply":"2022-11-19T18:07:57.085936Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"array([[ 1976,  1364],\n       [ 5062, 10912]])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_train_t, y_pred_train))","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:08:57.073097Z","iopub.execute_input":"2022-11-19T18:08:57.073468Z","iopub.status.idle":"2022-11-19T18:08:57.122063Z","shell.execute_reply.started":"2022-11-19T18:08:57.073437Z","shell.execute_reply":"2022-11-19T18:08:57.121057Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.28      0.59      0.38      3340\n         1.0       0.89      0.68      0.77     15974\n\n    accuracy                           0.67     19314\n   macro avg       0.58      0.64      0.58     19314\nweighted avg       0.78      0.67      0.70     19314\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test_t, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-11-19T18:09:21.725016Z","iopub.execute_input":"2022-11-19T18:09:21.725450Z","iopub.status.idle":"2022-11-19T18:09:21.750662Z","shell.execute_reply.started":"2022-11-19T18:09:21.725404Z","shell.execute_reply":"2022-11-19T18:09:21.749674Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.51      0.39      0.44      3439\n         1.0       0.47      0.59      0.52      3103\n\n    accuracy                           0.49      6542\n   macro avg       0.49      0.49      0.48      6542\nweighted avg       0.49      0.49      0.48      6542\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}